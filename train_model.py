import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib
import os

# ğŸ“ íŒŒì¼ ê²½ë¡œ ì„¤ì •
DATA_FILE = "ML_asos_dataset.csv"
MODEL_FILE = "trained_model.pkl"
FEATURE_FILE = "feature_names.pkl"

# âœ… 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv(DATA_FILE, encoding="utf-8-sig")

# âœ… 2. ì „ì²˜ë¦¬
X = df[["ìµœê³ ì²´ê°ì˜¨ë„(Â°C)", "ìµœê³ ê¸°ì˜¨(Â°C)", "í‰ê· ê¸°ì˜¨(Â°C)", "ìµœì €ê¸°ì˜¨(Â°C)", "í‰ê· ìƒëŒ€ìŠµë„(%)"]]
y = df["í™˜ììˆ˜"]

# âœ… 3. í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# âœ… 4. ëª¨ë¸ í•™ìŠµ
model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
model.fit(X_train, y_train)

# âœ… 5. ì˜ˆì¸¡ ë° ì„±ëŠ¥ ì¶œë ¥ (ì„ íƒì )
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)
r2 = r2_score(y_test, y_pred)

print("ğŸ“Š Model Performance:")
print(f"MAE: {mae:.2f} / RMSE: {rmse:.2f} / RÂ²: {r2:.4f}")

# âœ… 6. ëª¨ë¸ ë° í”¼ì²˜ ì €ì¥
joblib.dump(model, MODEL_FILE)
joblib.dump(X.columns.tolist(), FEATURE_FILE)

print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ:", MODEL_FILE, FEATURE_FILE)
