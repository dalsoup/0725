import streamlit as st
import pandas as pd
import datetime
import joblib
import requests
import math
import os
import base64
from urllib.parse import unquote

# ----------------------- ğŸ“¦ ì„¤ì • -----------------------
st.set_page_config(layout="centered")
model = joblib.load("trained_model.pkl")
feature_names = joblib.load("feature_names.pkl")

KMA_API_KEY = unquote(st.secrets["KMA"]["API_KEY"])
ASOS_API_KEY = unquote(st.secrets["ASOS"]["API_KEY"])
GITHUB_USERNAME = st.secrets["GITHUB"]["USERNAME"]
GITHUB_REPO = st.secrets["GITHUB"]["REPO"]
GITHUB_BRANCH = st.secrets["GITHUB"]["BRANCH"]
GITHUB_TOKEN = st.secrets["GITHUB"]["TOKEN"]
GITHUB_FILENAME = "ML_asos_dataset.csv"

region_to_stn_id = {
    "ì„œìš¸íŠ¹ë³„ì‹œ": 108, "ë¶€ì‚°ê´‘ì—­ì‹œ": 159, "ëŒ€êµ¬ê´‘ì—­ì‹œ": 143, "ì¸ì²œê´‘ì—­ì‹œ": 112,
    "ê´‘ì£¼ê´‘ì—­ì‹œ": 156, "ëŒ€ì „ê´‘ì—­ì‹œ": 133, "ìš¸ì‚°ê´‘ì—­ì‹œ": 152, "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": 131,
    "ê²½ê¸°ë„": 119, "ê°•ì›ë„": 101, "ì¶©ì²­ë¶ë„": 131, "ì¶©ì²­ë‚¨ë„": 133,
    "ì „ë¼ë¶ë„": 146, "ì „ë¼ë‚¨ë„": 165, "ê²½ìƒë¶ë„": 137, "ê²½ìƒë‚¨ë„": 155, "ì œì£¼íŠ¹ë³„ìì¹˜ë„": 184
}

region_to_latlon = {
    "ì„œìš¸íŠ¹ë³„ì‹œ": (37.5665, 126.9780), "ë¶€ì‚°ê´‘ì—­ì‹œ": (35.1796, 129.0756), "ëŒ€êµ¬ê´‘ì—­ì‹œ": (35.8722, 128.6025),
    "ì¸ì²œê´‘ì—­ì‹œ": (37.4563, 126.7052), "ê´‘ì£¼ê´‘ì—­ì‹œ": (35.1595, 126.8526), "ëŒ€ì „ê´‘ì—­ì‹œ": (36.3504, 127.3845),
    "ìš¸ì‚°ê´‘ì—­ì‹œ": (35.5384, 129.3114), "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": (36.4800, 127.2890), "ê²½ê¸°ë„": (37.4138, 127.5183),
    "ê°•ì›ë„": (37.8228, 128.1555), "ì¶©ì²­ë¶ë„": (36.6358, 127.4917), "ì¶©ì²­ë‚¨ë„": (36.5184, 126.8000),
    "ì „ë¼ë¶ë„": (35.7167, 127.1442), "ì „ë¼ë‚¨ë„": (34.8161, 126.4630), "ê²½ìƒë¶ë„": (36.5760, 128.5056),
    "ê²½ìƒë‚¨ë„": (35.4606, 128.2132), "ì œì£¼íŠ¹ë³„ìì¹˜ë„": (33.4996, 126.5312)
}

# ----------------------- ğŸ” ê³µí†µ í•¨ìˆ˜ -----------------------
def convert_latlon_to_xy(lat, lon):
    RE, GRID = 6371.00877, 5.0
    SLAT1, SLAT2, OLON, OLAT = 30.0, 60.0, 126.0, 38.0
    XO, YO = 43, 136
    DEGRAD = math.pi / 180.0
    re = RE / GRID
    slat1, slat2 = SLAT1 * DEGRAD, SLAT2 * DEGRAD
    olon, olat = OLON * DEGRAD, OLAT * DEGRAD
    sn = math.log(math.cos(slat1)/math.cos(slat2)) / math.log(math.tan(math.pi/4+slat2/2)/math.tan(math.pi/4+slat1/2))
    sf = math.tan(math.pi/4+slat1/2)**sn * math.cos(slat1)/sn
    ro = re * sf / (math.tan(math.pi/4+olat/2)**sn)
    ra = re * sf / (math.tan(math.pi/4+lat*DEGRAD/2)**sn)
    theta = lon * DEGRAD - olon
    if theta > math.pi: theta -= 2*math.pi
    if theta < -math.pi: theta += 2*math.pi
    theta *= sn
    x = ra * math.sin(theta) + XO + 0.5
    y = ro - ra * math.cos(theta) + YO + 0.5
    return int(x), int(y)

def get_fixed_base_datetime(target_date):
    today = datetime.date.today()
    now = datetime.datetime.now()
    if target_date == today:
        hour = now.hour
        if hour >= 23: bt = "2300"
        elif hour >= 20: bt = "2000"
        elif hour >= 17: bt = "1700"
        elif hour >= 14: bt = "1400"
        elif hour >= 11: bt = "1100"
        elif hour >= 8: bt = "0800"
        elif hour >= 5: bt = "0500"
        else: bt = "0200"
        return today.strftime("%Y%m%d"), bt
    else:
        return today.strftime("%Y%m%d"), "0500"

def get_weather(region_name, target_date):
    latlon = region_to_latlon.get(region_name, (37.5665, 126.9780))
    nx, ny = convert_latlon_to_xy(*latlon)
    base_date, base_time = get_fixed_base_datetime(target_date)
    params = {
        "serviceKey": KMA_API_KEY,
        "numOfRows": "1000",
        "pageNo": "1",
        "dataType": "JSON",
        "base_date": base_date,
        "base_time": base_time,
        "nx": nx,
        "ny": ny
    }
    try:
        r = requests.get("http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst", params=params, timeout=10, verify=False)
        items = r.json().get("response", {}).get("body", {}).get("items", {}).get("item", [])
        df = pd.DataFrame(items)
        df["fcstDate"] = df["fcstDate"].astype(str)
        target_str = target_date.strftime("%Y%m%d")
        if target_str not in df["fcstDate"].values:
            return {}, base_date, base_time
        df = df[df["fcstDate"] == target_str]
        df = df[df["category"].isin(["T3H", "TMX", "TMN", "REH"])]
        summary = {}
        for cat in ["TMX", "TMN", "REH", "T3H"]:
            vals = df[df["category"] == cat]["fcstValue"].astype(float)
            if not vals.empty:
                summary[cat] = vals.mean() if cat in ["REH", "T3H"] else vals.iloc[0]
        return summary, base_date, base_time
    except:
        return {}, base_date, base_time

def get_asos_weather(region, ymd):
    stn_id = region_to_stn_id[region]
    url = f"http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey={ASOS_API_KEY}&pageNo=1&numOfRows=10&dataType=JSON&dataCd=ASOS&dateCd=DAY&startDt={ymd}&endDt={ymd}&stnIds={stn_id}"
    r = requests.get(url, timeout=10, verify=False)
    j = r.json()
    item = j.get("response", {}).get("body", {}).get("items", {}).get("item", [])[0]
    return {
        "TMX": float(item["maxTa"]),
        "TMN": float(item["minTa"]),
        "REH": float(item["avgRhm"])
    }

def get_risk_level(pred):
    if pred == 0: return "ğŸŸ¢ ë§¤ìš° ë‚®ìŒ"
    elif pred <= 2: return "ğŸŸ¡ ë‚®ìŒ"
    elif pred <= 5: return "ğŸŸ  ë³´í†µ"
    elif pred <= 10: return "ğŸ”´ ë†’ìŒ"
    else: return "ğŸ”¥ ë§¤ìš° ë†’ìŒ"

def predict_from_weather(tmx, tmn, reh):
    avg_temp = round((tmx + tmn) / 2, 1)
    input_df = pd.DataFrame([{ 
        "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)": tmx + 1.5,
        "ìµœê³ ê¸°ì˜¨(Â°C)": tmx,
        "í‰ê· ê¸°ì˜¨(Â°C)": avg_temp,
        "ìµœì €ê¸°ì˜¨(Â°C)": tmn,
        "í‰ê· ìƒëŒ€ìŠµë„(%)": reh
    }])
    X = input_df[feature_names] 
    pred = model.predict(X)[0]
    return pred, avg_temp, input_df

def get_last_year_patient_count(current_date, region, static_file="ML_7_8ì›”_2021_2025_dataset.xlsx"):
    try:
        # í˜„ì¬ ë‚ ì§œì˜ ì „ë…„ë„ ë‚ ì§œ êµ¬í•˜ê¸°
        last_year_date = current_date - datetime.timedelta(days=365)

        # ì—‘ì…€ íŒŒì¼ ì½ê¸°
        df_all = pd.read_excel(static_file, engine="openpyxl")

        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        df_all["ì¼ì‹œ"] = pd.to_datetime("1899-12-30") + pd.to_timedelta(df_all["ì¼ì‹œ"], unit="D")
        df_all["ì¼ì"] = df_all["ì¼ì‹œ"].dt.strftime("%Y-%m-%d")

        # ì „ë…„ë„ ë™ì¼ ì¼ìì˜ ë°ì´í„° í•„í„°ë§
        cond = (df_all["ì¼ì"] == last_year_date.strftime("%Y-%m-%d")) & (df_all["ê´‘ì—­ìì¹˜ë‹¨ì²´"] == region)
        row = df_all[cond]

        if not row.empty:
            return int(row["í™˜ììˆ˜"].values[0])
        else:
            return None
    except Exception as e:
        return None

# ----------------------- ğŸ§­ UI ì‹œì‘ -----------------------
st.title("HeatAI")
tab1, tab2 = st.tabs(["ğŸ“Š í­ì—¼íŠ¸ë¦¬ê±° ì˜ˆì¸¡í•˜ê¸°", "ğŸ“¥ AI í•™ìŠµ ë°ì´í„° ì¶”ê°€"])
# ====================================================================
# ğŸ”® ì˜ˆì¸¡ íƒ­
# ====================================================================
with tab1:
    st.header("ğŸ“Š í­ì—¼íŠ¸ë¦¬ê±° ì˜ˆì¸¡í•˜ê¸°")
    
    # ğŸ“… ë‚ ì§œ ì œí•œ: ì˜¤ëŠ˜ ~ ì˜¤ëŠ˜ + 4ì¼
    today = datetime.date.today()
    min_pred_date = today
    max_pred_date = today + datetime.timedelta(days=4)

    region = st.selectbox("ì§€ì—­ ì„ íƒ", list(region_to_stn_id.keys()), key="region_pred")
    date_selected = st.date_input(
        "ë‚ ì§œ ì„ íƒ",
        value=today,
        min_value=min_pred_date,
        max_value=max_pred_date
    )

    if st.button("ğŸ” ì˜ˆì¸¡í•˜ê¸°"):
        if date_selected >= today:
            weather, base_date, base_time = get_weather(region, date_selected)
        else:
            ymd = date_selected.strftime("%Y%m%d")
            weather = get_asos_weather(region, ymd)

        if not weather:
            st.error("âŒ ê¸°ìƒ ì •ë³´ ì—†ìŒ")
            st.stop()

        tmx, tmn, reh = weather.get("TMX", 0), weather.get("TMN", 0), weather.get("REH", 0)
        pred, avg_temp, input_df = predict_from_weather(tmx, tmn, reh)
        risk = get_risk_level(pred)

        st.markdown("#### â˜ï¸ ê¸°ìƒì •ë³´")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ìµœê³ ê¸°ì˜¨", f"{tmx:.1f}â„ƒ")
        col2.metric("ìµœì €ê¸°ì˜¨", f"{tmn:.1f}â„ƒ")
        col3.metric("í‰ê· ê¸°ì˜¨", f"{avg_temp:.1f}â„ƒ")
        col4.metric("ìŠµë„", f"{reh:.1f}%")

        with st.expander("ğŸ§ª ì…ë ¥ê°’ í™•ì¸"):
            st.dataframe(input_df)

        st.markdown("#### ğŸ’¡ ì˜ˆì¸¡ ê²°ê³¼")
        c1, c2 = st.columns(2)
        c1.metric("ì˜ˆì¸¡ í™˜ì ìˆ˜", f"{pred:.2f}ëª…")
        c2.metric("ìœ„í—˜ ë“±ê¸‰", risk)

        # ì „ë…„ë„ í™˜ì ìˆ˜ ë¹„êµ
        last_year_count = get_last_year_patient_count(date_selected, region)
        if last_year_count is not None:
            delta_from_last_year = pred - last_year_count
            st.markdown(f"ğŸ“… **ì „ë…„ë„({(date_selected - datetime.timedelta(days=365)).strftime('%Y-%m-%d')}) ë™ì¼ ë‚ ì§œ í™˜ììˆ˜**: **{last_year_count}ëª…**")
            st.markdown(f"ğŸ“ˆ **ì „ë…„ ëŒ€ë¹„ ì¦ê°**: {'+' if delta_from_last_year >= 0 else ''}{delta_from_last_year:.1f}ëª…")
        else:
            st.markdown("ğŸ“­ ì „ë…„ë„ ë™ì¼ ë‚ ì§œì˜ í™˜ì ìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ====================================================================
# ğŸ“¥ AI í•™ìŠµ ë°ì´í„° ì¶”ê°€
# ====================================================================
with tab2:
    with st.expander("â„¹ï¸ tab2 ì‚¬ìš©ë²•"):
        st.markdown("""
        **âœ… ì‚¬ìš© ë°©ë²•**  
        1. ë‚ ì§œì™€ ìì¹˜êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.  
        2. ì•„ë˜ ë§í¬ì—ì„œ ì§ˆë³‘ì²­ì˜ ì˜¨ì—´ì§ˆí™˜ì ì—‘ì…€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ ì—…ë¡œë“œí•˜ì„¸ìš”.  
           ğŸ‘‰ [ì˜¨ì—´ì§ˆí™˜ ì‘ê¸‰ì‹¤ê°ì‹œì²´ê³„ ë‹¤ìš´ë¡œë“œ](https://www.kdca.go.kr/board/board.es?mid=a20205030102&bid=0004&&cg_code=C01)  
        3. **ì €ì¥í•˜ê¸°** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´, í•´ë‹¹ ë°ì´í„°ëŠ” tab3ì˜ ìì¹˜êµ¬ë³„ í”¼í•´ì ìˆ˜ ì‚°ì •ì„ ìœ„í•œ ì…ë ¥ê°’ìœ¼ë¡œ ìë™ ë°˜ì˜ë©ë‹ˆë‹¤.
        """)

    st.header("ğŸ“¥ ìì¹˜êµ¬ë³„ ì‹¤ì œ í­ì—¼ ë°ì´í„° ì €ì¥í•˜ê¸°")

# âœ… 1. ë‚ ì§œ, ê´‘ì—­ì‹œë„, ìì¹˜êµ¬ ì„ íƒ
today = datetime.date.today()
min_record_date = datetime.date(2021, 5, 1)
max_record_date = today - datetime.timedelta(days=1)

date_selected = st.date_input("ğŸ“… ê¸°ë¡í•  ë‚ ì§œ", value=max_record_date, min_value=min_record_date, max_value=max_record_date)
region = st.selectbox("ğŸŒ ê´‘ì—­ì‹œë„ ì„ íƒ", ["ì„œìš¸íŠ¹ë³„ì‹œ"], key="region_excel")
gu = st.selectbox("ğŸ˜ï¸ ìì¹˜êµ¬ ì„ íƒ", [
    'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬', 'ê´‘ì§„êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬', 'ì„±ë¶êµ¬', 'ê°•ë¶êµ¬', 'ë„ë´‰êµ¬',
    'ë…¸ì›êµ¬', 'ì€í‰êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ë§ˆí¬êµ¬', 'ì–‘ì²œêµ¬', 'ê°•ì„œêµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ì˜ë“±í¬êµ¬',
    'ë™ì‘êµ¬', 'ê´€ì•…êµ¬', 'ì„œì´ˆêµ¬', 'ê°•ë‚¨êµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬'
])

# âœ… 2. ì§ˆë³‘ì²­ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“ ì§ˆë³‘ì²­ í™˜ììˆ˜ íŒŒì¼ ì—…ë¡œë“œ (.xlsx, ì‹œíŠ¸ëª…: ì„œìš¸íŠ¹ë³„ì‹œ)", type=["xlsx"])
    if uploaded_file:
    try:
        df_raw = pd.read_excel(uploaded_file, sheet_name="ì„œìš¸íŠ¹ë³„ì‹œ", header=None)
        districts = df_raw.iloc[0, 1::2].tolist()
        dates = df_raw.iloc[3:, 0].tolist()
        df_values = df_raw.iloc[3:, 1::2]
        df_values.columns = districts
        df_values.insert(0, "ì¼ì", dates)
        df_long = df_values.melt(id_vars=["ì¼ì"], var_name="ìì¹˜êµ¬", value_name="í™˜ììˆ˜")
        df_long["ì¼ì"] = pd.to_datetime(df_long["ì¼ì"], errors="coerce").dt.strftime("%Y-%m-%d")
        df_long["í™˜ììˆ˜"] = pd.to_numeric(df_long["í™˜ììˆ˜"], errors="coerce").fillna(0).astype(int)
        df_long["ì§€ì—­"] = "ì„œìš¸íŠ¹ë³„ì‹œ"

        # âœ… 3. ì„ íƒëœ ë‚ ì§œ+ìì¹˜êµ¬ì˜ í™˜ììˆ˜ í™•ì¸
        ymd = date_selected.strftime("%Y-%m-%d")
        selected = df_long[(df_long["ì¼ì"] == ymd) & (df_long["ìì¹˜êµ¬"] == gu)]
        if selected.empty:
            st.warning(f"âŒ {ymd} {gu} í™˜ììˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
        í™˜ììˆ˜ = int(selected["í™˜ììˆ˜"].values[0])

        # âœ… 4. ê¸°ìƒì²­ ASOS APIë¡œ ì‹¤ì œ ê¸°ì˜¨ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        from app import get_asos_weather  # ê¸°ì¡´ í•¨ìˆ˜ ì¬í™œìš©
        weather = get_asos_weather(region, ymd.replace("-", ""))
        tmx = weather.get("TMX", 0)
        tmn = weather.get("TMN", 0)
        reh = weather.get("REH", 0)
        avg_temp = round((tmx + tmn) / 2, 1)

        # âœ… 5. í†µí•© í‘œ í‘œì‹œ
        st.markdown("### âœ… ì €ì¥ë  í•™ìŠµ ë°ì´í„°")
            preview_df = pd.DataFrame([{ 
                "ì¼ì": ymd,
                "ì§€ì—­": region,
                "ìì¹˜êµ¬": gu,
                "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)": tmx + 1.5,
                "ìµœê³ ê¸°ì˜¨(Â°C)": tmx,
                "í‰ê· ê¸°ì˜¨(Â°C)": avg_temp,
                "ìµœì €ê¸°ì˜¨(Â°C)": tmn,
                "í‰ê· ìƒëŒ€ìŠµë„(%)": reh,
                "í™˜ììˆ˜": í™˜ììˆ˜
            }])

        # âœ… 6. GitHub ì €ì¥ ë²„íŠ¼
        if st.button("ğŸ’¾ GitHubì— ì €ì¥í•˜ê¸°"):
            csv_path = "ML_asos_dataset.csv"
            if os.path.exists(csv_path):
                try:
                    existing = pd.read_csv(csv_path, encoding="utf-8-sig")
                except UnicodeDecodeError:
                    existing = pd.read_csv(csv_path, encoding="cp949")
                existing = existing[~((existing["ì¼ì"] == ymd) & (existing["ìì¹˜êµ¬"] == gu))]
                df_all = pd.concat([existing, preview_df], ignore_index=True)
            else:
                df_all = preview_df

            df_all.to_csv(csv_path, index=False, encoding="utf-8-sig")

            # âœ… GitHub API ì—…ë¡œë“œ
            from urllib.parse import unquote
            GITHUB_USERNAME = st.secrets["GITHUB"]["USERNAME"]
            GITHUB_REPO = st.secrets["GITHUB"]["REPO"]
            GITHUB_BRANCH = st.secrets["GITHUB"]["BRANCH"]
            GITHUB_TOKEN = st.secrets["GITHUB"]["TOKEN"]
            GITHUB_FILENAME = "ML_asos_dataset.csv"

            with open(csv_path, "rb") as f:
                content = f.read()
            b64_content = base64.b64encode(content).decode("utf-8")

            api_url = f"https://api.github.com/repos/{GITHUB_USERNAME}/{GITHUB_REPO}/contents/{GITHUB_FILENAME}"
            r = requests.get(api_url, headers={"Authorization": f"Bearer {GITHUB_TOKEN}"})
            sha = r.json().get("sha") if r.status_code == 200 else None

            payload = {
                "message": f"Update {GITHUB_FILENAME} with new data for {ymd} {region} {gu}",
                "content": b64_content,
                "branch": GITHUB_BRANCH
            }
            if sha:
                payload["sha"] = sha

            headers = {
                "Authorization": f"Bearer {GITHUB_TOKEN}",
                "Accept": "application/vnd.github+json"
            }
            r = requests.put(api_url, headers=headers, json=payload)
            if r.status_code in [200, 201]:
                st.success("âœ… GitHub ì €ì¥ ì™„ë£Œ")
                st.info(f"ğŸ”— [íŒŒì¼ ë°”ë¡œ í™•ì¸í•˜ê¸°](https://github.com/{GITHUB_USERNAME}/{GITHUB_REPO}/blob/{GITHUB_BRANCH}/{GITHUB_FILENAME})")
            else:
                st.warning(f"âš ï¸ GitHub ì €ì¥ ì‹¤íŒ¨: {r.status_code} {r.text[:200]}")

    except Exception as e:
        st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

