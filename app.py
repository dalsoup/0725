import streamlit as st
import pandas as pd
import datetime
import requests
import os
import base64
from urllib.parse import unquote

from utils import (
    get_weather, get_asos_weather, get_risk_level,
    calculate_avg_temp, region_to_stn_id
)
from model_utils import predict_from_weather

# ----------------------- ğŸ“¦ ì„¤ì • -----------------------
st.set_page_config(layout="centered")

KMA_API_KEY = unquote(st.secrets["KMA"]["API_KEY"])
ASOS_API_KEY = unquote(st.secrets["ASOS"]["API_KEY"])
GITHUB_USERNAME = st.secrets["GITHUB"]["USERNAME"]
GITHUB_REPO = st.secrets["GITHUB"]["REPO"]
GITHUB_BRANCH = st.secrets["GITHUB"]["BRANCH"]
GITHUB_TOKEN = st.secrets["GITHUB"]["TOKEN"]
GITHUB_FILENAME = "ML_asos_dataset.csv"

# ----------------------- ğŸ§­ UI ì‹œì‘ -----------------------
st.title("HeatAI")
tab1, tab2 = st.tabs(["ğŸ“Š í­ì—¼íŠ¸ë¦¬ê±° ì˜ˆì¸¡í•˜ê¸°", "ğŸ“¥ AI í•™ìŠµ ë°ì´í„° ì¶”ê°€"])

# ====================================================================
# ğŸ”® ì˜ˆì¸¡ íƒ­
# ====================================================================
with tab1:
    st.header("ğŸ“Š í­ì—¼íŠ¸ë¦¬ê±° ì˜ˆì¸¡í•˜ê¸°")

    today = datetime.date.today()
    min_pred_date = today
    max_pred_date = today + datetime.timedelta(days=4)

    region = st.selectbox("ì§€ì—­ ì„ íƒ", list(region_to_stn_id.keys()), key="region_tab1")
    date_selected = st.date_input("ë‚ ì§œ ì„ íƒ", value=today, min_value=min_pred_date, max_value=max_pred_date, key="date_tab1")

    if st.button("ğŸ” ì˜ˆì¸¡í•˜ê¸°", key="predict_tab1"):
        if date_selected >= today:
            weather, base_date, base_time = get_weather(region, date_selected, KMA_API_KEY)
        else:
            ymd = date_selected.strftime("%Y%m%d")
            weather = get_asos_weather(region, ymd, ASOS_API_KEY)

        if not weather:
            st.error("âŒ ê¸°ìƒ ì •ë³´ ì—†ìŒ")
            st.stop()

        tmx, tmn, reh = weather.get("TMX", 0), weather.get("TMN", 0), weather.get("REH", 0)
        pred, avg_temp, input_df = predict_from_weather(tmx, tmn, reh)
        risk = get_risk_level(pred)

        st.markdown("#### â˜ï¸ ê¸°ìƒì •ë³´")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ìµœê³ ê¸°ì˜¨", f"{tmx:.1f}â„ƒ")
        col2.metric("ìµœì €ê¸°ì˜¨", f"{tmn:.1f}â„ƒ")
        col3.metric("í‰ê· ê¸°ì˜¨", f"{avg_temp:.1f}â„ƒ")
        col4.metric("ìŠµë„", f"{reh:.1f}%")

        with st.expander("ğŸ§ª ì…ë ¥ê°’ í™•ì¸"):
            st.dataframe(input_df)

        st.markdown("#### ğŸ’¡ ì˜ˆì¸¡ ê²°ê³¼")
        c1, c2 = st.columns(2)
        c1.metric("ì˜ˆì¸¡ í™˜ì ìˆ˜", f"{pred:.2f}ëª…")
        c2.metric("ìœ„í—˜ ë“±ê¸‰", risk)

        def get_last_year_patient_count(current_date, region, static_file="ML_7_8ì›”_2021_2025_dataset.xlsx"):
            try:
                last_year_date = current_date - datetime.timedelta(days=365)
                df_all = pd.read_excel(static_file, engine="openpyxl")
                df_all["ì¼ì‹œ"] = pd.to_datetime("1899-12-30") + pd.to_timedelta(df_all["ì¼ì‹œ"], unit="D")
                df_all["ì¼ì"] = df_all["ì¼ì‹œ"].dt.strftime("%Y-%m-%d")
                cond = (df_all["ì¼ì"] == last_year_date.strftime("%Y-%m-%d")) & (df_all["ê´‘ì—­ìì¹˜ë‹¨ì²´"] == region)
                row = df_all[cond]
                if not row.empty:
                    return int(row["í™˜ììˆ˜"].values[0])
                else:
                    return None
            except:
                return None

        last_year_count = get_last_year_patient_count(date_selected, region)
        if last_year_count is not None:
            delta = pred - last_year_count
            st.markdown(f"ğŸ“… **ì „ë…„ë„({(date_selected - datetime.timedelta(days=365)).strftime('%Y-%m-%d')}) ë™ì¼ ë‚ ì§œ í™˜ììˆ˜**: **{last_year_count}ëª…**")
            st.markdown(f"ğŸ“ˆ **ì „ë…„ ëŒ€ë¹„ ì¦ê°**: {'+' if delta >= 0 else ''}{delta:.1f}ëª…")
        else:
            st.markdown("ğŸ“­ ì „ë…„ë„ ë™ì¼ ë‚ ì§œì˜ í™˜ì ìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ====================================================================
# ğŸ“¥ AI í•™ìŠµ ë°ì´í„° ì¶”ê°€
# ====================================================================
with tab2:
    with st.expander("â„¹ï¸ tab2 ì‚¬ìš©ë²•"):
        st.markdown("""
        **âœ… ì‚¬ìš© ë°©ë²•**  
        1. ë‚ ì§œì™€ ìì¹˜êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.  
        2. ì•„ë˜ ë§í¬ì—ì„œ ì§ˆë³‘ì²­ì˜ ì˜¨ì—´ì§ˆí™˜ì ì—‘ì…€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ ì—…ë¡œë“œí•˜ì„¸ìš”.  
           ğŸ‘‰ [ì˜¨ì—´ì§ˆí™˜ ì‘ê¸‰ì‹¤ê°ì‹œì²´ê³„ ë‹¤ìš´ë¡œë“œ](https://www.kdca.go.kr/board/board.es?mid=a20205030102&bid=0004&&cg_code=C01)  
        3. **ì €ì¥í•˜ê¸°** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´, í•´ë‹¹ ë°ì´í„°ëŠ” tab3ì˜ ìì¹˜êµ¬ë³„ í”¼í•´ì ìˆ˜ ì‚°ì •ì„ ìœ„í•œ ì…ë ¥ê°’ìœ¼ë¡œ ìë™ ë°˜ì˜ë©ë‹ˆë‹¤.
        """)

    st.header("ğŸ“¥ ìì¹˜êµ¬ë³„ ì‹¤ì œ í­ì—¼ ë°ì´í„° ì €ì¥í•˜ê¸°")

    today = datetime.date.today()
    min_record_date = datetime.date(2021, 5, 1)
    max_record_date = today - datetime.timedelta(days=1)

    date_selected = st.date_input("ğŸ“… ê¸°ë¡í•  ë‚ ì§œ", value=max_record_date, min_value=min_record_date, max_value=max_record_date, key="date_tab2")
    region = st.selectbox("ğŸŒ ê´‘ì—­ì‹œë„ ì„ íƒ", ["ì„œìš¸íŠ¹ë³„ì‹œ"], key="region_tab2")
    gu = st.selectbox("ğŸ˜ï¸ ìì¹˜êµ¬ ì„ íƒ", [
        'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬', 'ê´‘ì§„êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬', 'ì„±ë¶êµ¬', 'ê°•ë¶êµ¬', 'ë„ë´‰êµ¬',
        'ë…¸ì›êµ¬', 'ì€í‰êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ë§ˆí¬êµ¬', 'ì–‘ì²œêµ¬', 'ê°•ì„œêµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ì˜ë“±í¬êµ¬',
        'ë™ì‘êµ¬', 'ê´€ì•…êµ¬', 'ì„œì´ˆêµ¬', 'ê°•ë‚¨êµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬'
    ], key="gu_tab2")

    uploaded_file = st.file_uploader("ğŸ“ ì§ˆë³‘ì²­ í™˜ììˆ˜ íŒŒì¼ ì—…ë¡œë“œ (.xlsx, ì‹œíŠ¸ëª…: ì„œìš¸íŠ¹ë³„ì‹œ)", type=["xlsx"], key="upload_tab2")

    if uploaded_file:
        try:
            df_raw = pd.read_excel(uploaded_file, sheet_name="ì„œìš¸íŠ¹ë³„ì‹œ", header=None)
            districts = df_raw.iloc[0, 1::2].tolist()
            dates = df_raw.iloc[3:, 0].tolist()
            df_values = df_raw.iloc[3:, 1::2]
            df_values.columns = districts
            df_values.insert(0, "ì¼ì", dates)
            df_long = df_values.melt(id_vars=["ì¼ì"], var_name="ìì¹˜êµ¬", value_name="í™˜ììˆ˜")
            df_long["ì¼ì"] = pd.to_datetime(df_long["ì¼ì"], errors="coerce").dt.strftime("%Y-%m-%d")
            df_long["í™˜ììˆ˜"] = pd.to_numeric(df_long["í™˜ììˆ˜"], errors="coerce").fillna(0).astype(int)
            df_long["ì§€ì—­"] = "ì„œìš¸íŠ¹ë³„ì‹œ"

            ymd = date_selected.strftime("%Y-%m-%d")
            selected = df_long[(df_long["ì¼ì"] == ymd) & (df_long["ìì¹˜êµ¬"] == gu)]
            if selected.empty:
                st.warning(f"âŒ {ymd} {gu} í™˜ììˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
            í™˜ììˆ˜ = int(selected["í™˜ììˆ˜"].values[0])

            weather = get_asos_weather(region, ymd.replace("-", ""), ASOS_API_KEY)
            tmx = weather.get("TMX", 0)
            tmn = weather.get("TMN", 0)
            reh = weather.get("REH", 0)
            avg_temp = calculate_avg_temp(tmx, tmn)

            st.markdown("### âœ… ì €ì¥ë  í•™ìŠµ ë°ì´í„°")
            preview_df = pd.DataFrame([{ 
                "ì¼ì": ymd,
                "ì§€ì—­": region,
                "ìì¹˜êµ¬": gu,
                "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)": tmx + 1.5,
                "ìµœê³ ê¸°ì˜¨(Â°C)": tmx,
                "í‰ê· ê¸°ì˜¨(Â°C)": avg_temp,
                "ìµœì €ê¸°ì˜¨(Â°C)": tmn,
                "í‰ê· ìƒëŒ€ìŠµë„(%)": reh,
                "í™˜ììˆ˜": í™˜ììˆ˜
            }])
            st.dataframe(preview_df)

            if st.button("ğŸ’¾ GitHubì— ì €ì¥í•˜ê¸°", key="save_tab2"):
                csv_path = "ML_asos_dataset.csv"
                if os.path.exists(csv_path):
                    try:
                        existing = pd.read_csv(csv_path, encoding="utf-8-sig")
                    except UnicodeDecodeError:
                        existing = pd.read_csv(csv_path, encoding="cp949")
                    existing = existing[~((existing["ì¼ì"] == ymd) & (existing["ìì¹˜êµ¬"] == gu))]
                    df_all = pd.concat([existing, preview_df], ignore_index=True)
                else:
                    df_all = preview_df

                df_all.to_csv(csv_path, index=False, encoding="utf-8-sig")

                with open(csv_path, "rb") as f:
                    content = f.read()
                b64_content = base64.b64encode(content).decode("utf-8")

                api_url = f"https://api.github.com/repos/{GITHUB_USERNAME}/{GITHUB_REPO}/contents/{GITHUB_FILENAME}"
                r = requests.get(api_url, headers={"Authorization": f"Bearer {GITHUB_TOKEN}"})
                sha = r.json().get("sha") if r.status_code == 200 else None

                payload = {
                    "message": f"Update {GITHUB_FILENAME} with new data for {ymd} {region} {gu}",
                    "content": b64_content,
                    "branch": GITHUB_BRANCH
                }
                if sha:
                    payload["sha"] = sha

                headers = {
                    "Authorization": f"Bearer {GITHUB_TOKEN}",
                    "Accept": "application/vnd.github+json"
                }
                r = requests.put(api_url, headers=headers, json=payload)
                if r.status_code in [200, 201]:
                    st.success("âœ… GitHub ì €ì¥ ì™„ë£Œ")
                    st.info(f"ğŸ”— [íŒŒì¼ ë°”ë¡œ í™•ì¸í•˜ê¸°](https://github.com/{GITHUB_USERNAME}/{GITHUB_REPO}/blob/{GITHUB_BRANCH}/{GITHUB_FILENAME})")
                else:
                    st.warning(f"âš ï¸ GitHub ì €ì¥ ì‹¤íŒ¨: {r.status_code} {r.text[:200]}")

        except Exception as e:
            st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
