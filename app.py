import streamlit as st
import pandas as pd
import datetime
import joblib
import requests
import math
from urllib.parse import unquote
import os
import base64

st.set_page_config(layout="centered")
model = joblib.load("trained_model.pkl")
feature_names = joblib.load("feature_names.pkl")
KMA_API_KEY = unquote(st.secrets["KMA"]["API_KEY"])
ASOS_API_KEY = unquote(st.secrets["ASOS"]["API_KEY"])
GITHUB_USERNAME = st.secrets["GITHUB"]["USERNAME"]
GITHUB_REPO = st.secrets["GITHUB"]["REPO"]
GITHUB_BRANCH = st.secrets["GITHUB"]["BRANCH"]
GITHUB_TOKEN = st.secrets["GITHUB"]["TOKEN"]
GITHUB_FILENAME = "ML_asos_dataset.csv"

st.set_page_config(layout="centered")
model = joblib.load("trained_model.pkl")
feature_names = joblib.load("feature_names.pkl")
KMA_API_KEY = unquote(st.secrets["KMA"]["API_KEY"])
ASOS_API_KEY = unquote(st.secrets["ASOS"]["API_KEY"])

region_to_stn_id = {
    "ì„œìš¸íŠ¹ë³„ì‹œ": 108, "ë¶€ì‚°ê´‘ì—­ì‹œ": 159, "ëŒ€êµ¬ê´‘ì—­ì‹œ": 143, "ì¸ì²œê´‘ì—­ì‹œ": 112,
    "ê´‘ì£¼ê´‘ì—­ì‹œ": 156, "ëŒ€ì „ê´‘ì—­ì‹œ": 133, "ìš¸ì‚°ê´‘ì—­ì‹œ": 152, "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": 131,
    "ê²½ê¸°ë„": 119, "ê°•ì›ë„": 101, "ì¶©ì²­ë¶ë„": 131, "ì¶©ì²­ë‚¨ë„": 133,
    "ì „ë¼ë¶ë„": 146, "ì „ë¼ë‚¨ë„": 165, "ê²½ìƒë¶ë„": 137, "ê²½ìƒë‚¨ë„": 155, "ì œì£¼íŠ¹ë³„ìì¹˜ë„": 184
}

region_to_latlon = {
    "ì„œìš¸íŠ¹ë³„ì‹œ": (37.5665, 126.9780), "ë¶€ì‚°ê´‘ì—­ì‹œ": (35.1796, 129.0756), "ëŒ€êµ¬ê´‘ì—­ì‹œ": (35.8722, 128.6025),
    "ì¸ì²œê´‘ì—­ì‹œ": (37.4563, 126.7052), "ê´‘ì£¼ê´‘ì—­ì‹œ": (35.1595, 126.8526), "ëŒ€ì „ê´‘ì—­ì‹œ": (36.3504, 127.3845),
    "ìš¸ì‚°ê´‘ì—­ì‹œ": (35.5384, 129.3114), "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": (36.4800, 127.2890), "ê²½ê¸°ë„": (37.4138, 127.5183),
    "ê°•ì›ë„": (37.8228, 128.1555), "ì¶©ì²­ë¶ë„": (36.6358, 127.4917), "ì¶©ì²­ë‚¨ë„": (36.5184, 126.8000),
    "ì „ë¼ë¶ë„": (35.7167, 127.1442), "ì „ë¼ë‚¨ë„": (34.8161, 126.4630), "ê²½ìƒë¶ë„": (36.5760, 128.5056),
    "ê²½ìƒë‚¨ë„": (35.4606, 128.2132), "ì œì£¼íŠ¹ë³„ìì¹˜ë„": (33.4996, 126.5312)
}

st.title("ğŸ”¥ ì˜¨ì—´ì§ˆí™˜ ì˜ˆì¸¡ ë° í•™ìŠµë°ì´í„° ê¸°ë¡ê¸°")
region = st.selectbox("ì§€ì—­ ì„ íƒ", list(region_to_stn_id.keys()))
today = datetime.date.today()
min_day = datetime.date(2021, 7, 1)
max_day = today + datetime.timedelta(days=5)
date_selected = st.date_input("ë‚ ì§œ ì„ íƒ", value=today, min_value=min_day, max_value=max_day)

use_asos = date_selected < today

# --- ì˜ˆì¸¡ or ê¸°ë¡ ë¶„ê¸° ---
if st.button("ì¡°íšŒí•˜ê¸°"):
    if not use_asos:
        st.info("ğŸ“¡ ì˜¤ëŠ˜ ì´í›„ â†’ ë‹¨ê¸°ì˜ˆë³´ API ê¸°ë°˜ ì˜ˆì¸¡")

        def convert_latlon_to_xy(lat, lon):
            RE, GRID = 6371.00877, 5.0
            SLAT1, SLAT2, OLON, OLAT = 30.0, 60.0, 126.0, 38.0
            XO, YO = 43, 136
            DEGRAD = math.pi / 180.0
            re = RE / GRID
            slat1, slat2 = SLAT1 * DEGRAD, SLAT2 * DEGRAD
            olon, olat = OLON * DEGRAD, OLAT * DEGRAD
            sn = math.log(math.cos(slat1)/math.cos(slat2)) / math.log(math.tan(math.pi/4+slat2/2)/math.tan(math.pi/4+slat1/2))
            sf = math.tan(math.pi/4+slat1/2)**sn * math.cos(slat1)/sn
            ro = re * sf / (math.tan(math.pi/4+olat/2)**sn)
            ra = re * sf / (math.tan(math.pi/4+lat*DEGRAD/2)**sn)
            theta = lon * DEGRAD - olon
            if theta > math.pi: theta -= 2*math.pi
            if theta < -math.pi: theta += 2*math.pi
            theta *= sn
            x = ra * math.sin(theta) + XO + 0.5
            y = ro - ra * math.cos(theta) + YO + 0.5
            return int(x), int(y)

        def get_fixed_base_datetime(target_date):
            today = datetime.date.today()
            now = datetime.datetime.now()

            if target_date == today:
                hour = now.hour
                if hour >= 23: bt = "2300"
                elif hour >= 20: bt = "2000"
                elif hour >= 17: bt = "1700"
                elif hour >= 14: bt = "1400"
                elif hour >= 11: bt = "1100"
                elif hour >= 8: bt = "0800"
                elif hour >= 5: bt = "0500"
                else: bt = "0200"
                return today.strftime("%Y%m%d"), bt
            else:
                return today.strftime("%Y%m%d"), "0500"

        def get_weather(region_name, target_date):
            latlon = region_to_latlon.get(region_name, (37.5665, 126.9780))
            nx, ny = convert_latlon_to_xy(*latlon)
            base_date, base_time = get_fixed_base_datetime(target_date)

            params = {
                "serviceKey": KMA_API_KEY,
                "numOfRows": "1000",
                "pageNo": "1",
                "dataType": "JSON",
                "base_date": base_date,
                "base_time": base_time,
                "nx": nx,
                "ny": ny
            }

            try:
                r = requests.get("http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst", params=params, timeout=10, verify=False)
                items = r.json().get("response", {}).get("body", {}).get("items", {}).get("item", [])
                df = pd.DataFrame(items)
                df["fcstDate"] = df["fcstDate"].astype(str)
                target_str = target_date.strftime("%Y%m%d")

                if target_str not in df["fcstDate"].values:
                    st.error(f"âŒ ì˜ˆë³´ ë°ì´í„°ì— {target_str} ë‚ ì§œê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    return {}, base_date, base_time

                df = df[df["fcstDate"] == target_str]
                df = df[df["category"].isin(["T3H", "TMX", "TMN", "REH"])]

                summary = {}
                for cat in ["TMX", "TMN", "REH", "T3H"]:
                    vals = df[df["category"] == cat]["fcstValue"].astype(float)
                    if not vals.empty:
                        summary[cat] = vals.mean() if cat in ["REH", "T3H"] else vals.iloc[0]

                return summary, base_date, base_time

            except Exception as e:
                st.error(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                return {}, base_date, base_time

        def calculate_avg_temp(tmx, tmn):
            if tmx is not None and tmn is not None:
                return round((tmx + tmn) / 2, 1)
            return None

        weather, base_date, base_time = get_weather(region, date_selected)
        if not weather:
            st.stop()

        st.caption(f"ğŸ“¡ ì‚¬ìš©ëœ ì˜ˆë³´ ê¸°ì¤€ ì‹œê° â†’ base_date: `{base_date}`, base_time: `{base_time}`")

        tmx, tmn = weather.get("TMX"), weather.get("TMN")
        avg_temp = calculate_avg_temp(tmx, tmn)

        st.markdown("#### â˜ï¸ ì˜¤ëŠ˜ì˜ ê¸°ìƒì •ë³´")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ìµœê³ ê¸°ì˜¨", f"{tmx:.1f}â„ƒ" if tmx else "-")
        col2.metric("ìµœì €ê¸°ì˜¨", f"{tmn:.1f}â„ƒ" if tmn else "-")
        col3.metric("í‰ê· ê¸°ì˜¨", f"{avg_temp:.1f}â„ƒ" if avg_temp is not None else "-")
        col4.metric("ìŠµë„", f"{weather.get('REH', 0):.1f}%" if weather.get("REH") is not None else "-")

        input_df = pd.DataFrame([{
            "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)": tmx + 1.5 if tmx else 0,
            "ìµœê³ ê¸°ì˜¨(Â°C)": tmx or 0,
            "í‰ê· ê¸°ì˜¨(Â°C)": avg_temp or 0,
            "ìµœì €ê¸°ì˜¨(Â°C)": tmn or 0,
            "í‰ê· ìƒëŒ€ìŠµë„(%)": weather.get("REH", 0)
        }])

        st.subheader("ğŸ§ª ëª¨ë¸ ì…ë ¥ê°’ í™•ì¸")
        st.dataframe(input_df)

        X_input = input_df[feature_names].copy()
        X_input.columns = model.get_booster().feature_names

        pred = model.predict(X_input)[0]
        def get_risk_level(pred):
            if pred == 0: return "ğŸŸ¢ ë§¤ìš° ë‚®ìŒ"
            elif pred <= 2: return "ğŸŸ¡ ë‚®ìŒ"
            elif pred <= 5: return "ğŸŸ  ë³´í†µ"
            elif pred <= 10: return "ğŸ”´ ë†’ìŒ"
            else: return "ğŸ”¥ ë§¤ìš° ë†’ìŒ"
        risk = get_risk_level(pred)

        st.markdown("#### ğŸ’¡ ì˜¨ì—´ì§ˆí™˜ì ì˜ˆì¸¡")
        c1, c2 = st.columns(2)
        c1.metric("ì˜ˆì¸¡ í™˜ì ìˆ˜", f"{pred:.2f}ëª…")
        c2.metric("ìœ„í—˜ ë“±ê¸‰", risk)
        st.caption(f"ì „ë…„ë„ í‰ê· (6.8ëª…) ëŒ€ë¹„ {'+' if pred - 6.8 >= 0 else ''}{pred - 6.8:.1f}ëª…")

    else:
        st.info("ğŸ•° ê³¼ê±° ë‚ ì§œ â†’ ASOS + ì—‘ì…€ ê¸°ë°˜ í•™ìŠµë°ì´í„° ê¸°ë¡")

        # 1ï¸âƒ£ ASOS ê¸°ë°˜ ì˜ˆì¸¡ ë¨¼ì € ìˆ˜í–‰ (ì˜ˆì¸¡ ëª¨ë“œì™€ ë™ì¼)
        st.markdown("#### â˜ï¸ ì˜¤ëŠ˜ì˜ ê¸°ìƒì •ë³´ (ASOS ê¸°ì¤€)")
        stn_id = region_to_stn_id[region]
        ymd = date_selected.strftime("%Y%m%d")
        url = f"http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey={ASOS_API_KEY}&pageNo=1&numOfRows=10&dataType=JSON&dataCd=ASOS&dateCd=DAY&startDt={ymd}&endDt={ymd}&stnIds={stn_id}"
        r = requests.get(url, timeout=10, verify=False)
        if "application/json" not in r.headers.get("Content-Type", ""):
            st.error("âŒ JSON í˜•ì‹ì´ ì•„ë‹Œ ì‘ë‹µì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
            st.text(r.text[:500])
            st.stop()
        j = r.json()
        item = j.get("response", {}).get("body", {}).get("items", {}).get("item", [])[0]

        tmx = float(item["maxTa"])
        tmn = float(item["minTa"])
        reh = float(item["avgRhm"])
        avg = round((tmx + tmn) / 2, 1)

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ìµœê³ ê¸°ì˜¨", f"{tmx:.1f}â„ƒ")
        col2.metric("ìµœì €ê¸°ì˜¨", f"{tmn:.1f}â„ƒ")
        col3.metric("í‰ê· ê¸°ì˜¨", f"{avg:.1f}â„ƒ")
        col4.metric("ìŠµë„", f"{reh:.1f}%")

        input_df = pd.DataFrame([{
            "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)": round(tmx + 1.5, 1),
            "ìµœê³ ê¸°ì˜¨(Â°C)": tmx,
            "í‰ê· ê¸°ì˜¨(Â°C)": avg,
            "ìµœì €ê¸°ì˜¨(Â°C)": tmn,
            "í‰ê· ìƒëŒ€ìŠµë„(%)": reh
        }])

        st.subheader("ğŸ§ª ëª¨ë¸ ì…ë ¥ê°’ í™•ì¸")
        st.dataframe(input_df)

        X_input = input_df[feature_names].copy()
        X_input.columns = model.get_booster().feature_names

        pred = model.predict(X_input)[0]
        def get_risk_level(pred):
            if pred == 0: return "ğŸŸ¢ ë§¤ìš° ë‚®ìŒ"
            elif pred <= 2: return "ğŸŸ¡ ë‚®ìŒ"
            elif pred <= 5: return "ğŸŸ  ë³´í†µ"
            elif pred <= 10: return "ğŸ”´ ë†’ìŒ"
            else: return "ğŸ”¥ ë§¤ìš° ë†’ìŒ"
        risk = get_risk_level(pred)

        st.markdown("#### ğŸ’¡ ì˜¨ì—´ì§ˆí™˜ì ì˜ˆì¸¡")
        c1, c2 = st.columns(2)
        c1.metric("ì˜ˆì¸¡ í™˜ì ìˆ˜", f"{pred:.2f}ëª…")
        c2.metric("ìœ„í—˜ ë“±ê¸‰", risk)

        # 2ï¸âƒ£ ì—‘ì…€ ì—…ë¡œë“œë¡œ ì‹¤ì œ í™˜ììˆ˜ ì¶”ê°€ ê¸°ë¡
        with st.form(key=f"upload_form_{ymd}_{region}"):
            uploaded_file = st.file_uploader("ì§ˆë³‘ì²­ ì˜¨ì—´ì§ˆí™˜ ì—‘ì…€ ì—…ë¡œë“œ (ì‹œíŠ¸ëª… = ì§€ì—­ëª…)", type=["xlsx"])
            submit_upload = st.form_submit_button("ğŸ“¥ ì—…ë¡œë“œ ë° í•™ìŠµ ë°ì´í„° ì €ì¥")
        if uploaded_file and submit_upload:
            try:
                sheet_df = pd.read_excel(uploaded_file, sheet_name=region, engine="openpyxl")
                patient_col = [col for col in sheet_df.columns if "í™˜ììˆ˜" in col or "í™˜ì ìˆ˜" in col]
                date_col = [col for col in sheet_df.columns if "ì¼ì" in col or "ë‚ ì§œ" in col or "ê¸°ì¤€ì¼" in col]

                if not patient_col or not date_col:
                    st.error("âŒ ì‹œíŠ¸ì— 'í™˜ììˆ˜'ì™€ 'ì¼ì' ê´€ë ¨ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    st.stop()

                df = sheet_df[[date_col[0], patient_col[0]]].copy()
                df.columns = ["ì¼ì", "í™˜ììˆ˜"]
                df["ì¼ì"] = pd.to_datetime(df["ì¼ì"]).dt.date
                filtered = df[df["ì¼ì"] == date_selected]

                if filtered.empty:
                    st.warning("âš ï¸ í•´ë‹¹ ë‚ ì§œì— í™˜ììˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                í™˜ììˆ˜ = int(filtered.iloc[0]["í™˜ììˆ˜"])

                input_row = {
                    "ì¼ì": ymd,
                    "ì§€ì—­": region,
                    "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)": round(tmx + 1.5, 1),
                    "ìµœê³ ê¸°ì˜¨(Â°C)": tmx,
                    "í‰ê· ê¸°ì˜¨(Â°C)": avg,
                    "ìµœì €ê¸°ì˜¨(Â°C)": tmn,
                    "í‰ê· ìƒëŒ€ìŠµë„(%)": reh,
                    "í™˜ììˆ˜": í™˜ììˆ˜
                }

                st.success(f"âœ… {ymd} {region} â†’ í™˜ììˆ˜ {í™˜ììˆ˜}ëª… ê¸°ë¡ ì™„ë£Œ")
                st.dataframe(pd.DataFrame([input_row]))

                csv_path = "ML_asos_dataset.csv"
                if os.path.exists(csv_path):
                    existing = pd.read_csv(csv_path)
                    existing = existing[~((existing["ì¼ì"] == ymd) & (existing["ì§€ì—­"] == region))]
                    df = pd.concat([existing, pd.DataFrame([input_row])], ignore_index=True)
                else:
                    df = pd.DataFrame([input_row])

                df.to_csv(GITHUB_FILENAME, index=False, encoding="utf-8-sig")

                try:
                    # GitHubì— ì—…ë¡œë“œ
                    with open(GITHUB_FILENAME, "rb") as f:
                        content = f.read()
                    b64_content = base64.b64encode(content).decode("utf-8")
                    api_url = f"https://api.github.com/repos/{GITHUB_USERNAME}/{GITHUB_REPO}/contents/{GITHUB_FILENAME}"

                    # ê¸°ì¡´ íŒŒì¼ SHA ê°€ì ¸ì˜¤ê¸° (ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸)
                    r = requests.get(api_url, headers={"Authorization": f"Bearer {GITHUB_TOKEN}"})
                    if r.status_code == 200:
                        sha = r.json()["sha"]
                    else:
                        sha = None

                    commit_msg = f"Update {GITHUB_FILENAME} with new data for {ymd} {region}"
                    payload = {
                        "message": commit_msg,
                        "content": b64_content,
                        "branch": GITHUB_BRANCH
                    }
                    if sha:
                        payload["sha"] = sha

                    headers = {
                        "Authorization": f"Bearer {GITHUB_TOKEN}",
                        "Accept": "application/vnd.github+json"
                    }
                    r = requests.put(api_url, headers=headers, json=payload)

                    if r.status_code in [200, 201]:
                        st.success("âœ… GitHub ì €ì¥ ì™„ë£Œ")
                    else:
                        st.warning(f"âš ï¸ GitHub ì €ì¥ ì‹¤íŒ¨: {r.status_code} {r.text[:200]}")

                except Exception as e:
                    st.error(f"âŒ GitHub ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

            except Exception as e:
                st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

