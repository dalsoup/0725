import streamlit as st
import pandas as pd
import datetime
import requests
import os
import base64
import io
from urllib.parse import unquote
import subprocess
import sys


from utils import (
    get_weather, get_asos_weather, get_risk_level,
    calculate_avg_temp, region_to_stn_id, compute_heat_index
)
from model_utils import predict_from_weather

# ----------------------- ğŸ“¦ ì„¤ì • -----------------------
st.set_page_config(layout="centered")

KMA_API_KEY = unquote(st.secrets["KMA"]["API_KEY"])
ASOS_API_KEY = unquote(st.secrets["ASOS"]["API_KEY"])
GITHUB_USERNAME = st.secrets["GITHUB"]["USERNAME"]
GITHUB_REPO = st.secrets["GITHUB"]["REPO"]
GITHUB_BRANCH = st.secrets["GITHUB"]["BRANCH"]
GITHUB_TOKEN = st.secrets["GITHUB"]["TOKEN"]
GITHUB_FILENAME = "ML_asos_dataset.csv"

# ----------------------- ğŸ§­ UI ì‹œì‘ -----------------------
st.title("HeatAI")
tab1, tab2, tab3 = st.tabs(["ğŸ“Š í­ì—¼ ì˜ˆì¸¡ ë° ìœ„í—˜ë„ ë¶„ì„", "ğŸ“¥ ì‹¤ì œ í”¼í•´ ê¸°ë¡ ë° ë°ì´í„° ì…ë ¥", "ğŸ“ ìì¹˜êµ¬ë³„ í”¼í•´ì ìˆ˜ ë° ë³´ìƒ ë¶„ì„"])

with tab1:
    # âœ… ì‚¬ìš©ë²• ì•ˆë‚´
    with st.expander("ğŸ“Š tab1ì—ì„œ ì…ë ¥ëœ ì •ë³´ëŠ” ì´ë ‡ê²Œ í™œìš©ë©ë‹ˆë‹¤"):
        st.markdown("""
        1. ê¸°ìƒì²­ì˜ ë‹¨ê¸°ì˜ˆë³´ APIë¥¼ í†µí•´ ìë™ìœ¼ë¡œ ìˆ˜ì§‘ëœ ê¸°ìƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ,  
           AIê°€ ì„ íƒí•œ ì§€ì—­ì˜ ì˜ˆì¸¡ ì˜¨ì—´ì§ˆí™˜ì ìˆ˜ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.

        2. ì˜ˆì¸¡ ëª¨ë¸ì€ 4ê°œë…„ 7,8ì›”ì˜ ì‹¤ì œ ê¸°ìƒ ì¡°ê±´ê³¼ ì˜¨ì—´ì§ˆí™˜ì ìˆ˜ ë°ì´í„°ë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.  
           í˜„ì¬ ì…ë ¥ëœ ê¸°ìƒ ì¡°ê±´ì´ ê³¼ê±° ì–´ë–¤ ë‚ ê³¼ ìœ ì‚¬í•œì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ  
           AIê°€ ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ì€ í™˜ì ìˆ˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.

        3. ì˜ˆì¸¡ëœ í™˜ì ìˆ˜ëŠ” ìœ„í—˜ë„ ë“±ê¸‰(ğŸŸ¢~ğŸ”¥)ìœ¼ë¡œ ë³€í™˜ë˜ì–´ ì‹œë¯¼ì—ê²Œ ì „ë‹¬ë˜ë©°,  
           tab3ì˜ ìì¹˜êµ¬ë³„ í”¼í•´ì ìˆ˜ ê³„ì‚°ì— í™œìš©ë˜ëŠ” ì…ë ¥ê°’(P_pred)ìœ¼ë¡œë„ ì‚¬ìš©ë©ë‹ˆë‹¤.

        ğŸ“ ê¸°ìƒì²­ ì˜ˆë³´ëŠ” ì§€ì  ë‹¨ìœ„(ê´‘ì—­ì‹œë„) ê¸°ì¤€ìœ¼ë¡œ ì œê³µë˜ë¯€ë¡œ,  
        í˜„ì¬ëŠ” ìì¹˜êµ¬ ë‹¨ìœ„ê°€ ì•„ë‹Œ ê´‘ì—­ì‹œë„ ë‹¨ìœ„ë¡œë§Œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

        ğŸ“… ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‚ ì§œëŠ” 2025ë…„ 7ì›” 1ì¼ë¶€í„° 8ì›” 31ì¼ê¹Œì§€ì…ë‹ˆë‹¤.
        """)

# âœ… ì‘ë…„ ë™ì¼ ë‚ ì§œ í™˜ì ìˆ˜ ì¡°íšŒ í•¨ìˆ˜
def get_last_year_patient_count(current_date, region, static_file="ML_7_8ì›”_2021_2025_dataset.xlsx"):
    try:
        last_year_date = (current_date - datetime.timedelta(days=365)).strftime("%Y-%m-%d")
        df_all = pd.read_excel(static_file, engine="openpyxl")

        # ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
        if "ì¼ì‹œ" in df_all.columns and pd.api.types.is_numeric_dtype(df_all["\uc77c\uc2dc"]):
            df_all["\uc77c\uc2dc"] = pd.to_datetime("1899-12-30") + pd.to_timedelta(df_all["\uc77c\uc2dc"], unit="D")
            df_all["\uc77c\uc790"] = df_all["\uc77c\uc2dc"].dt.strftime("%Y-%m-%d")
        elif "ì¼ì" not in df_all.columns and "ì¼ì‹œ" in df_all.columns:
            df_all["\uc77c\uc790"] = pd.to_datetime(df_all["\uc77c\uc2dc"]).dt.strftime("%Y-%m-%d")

        cond = (df_all["\uc77c\uc790"] == last_year_date) & (df_all["\uad11\uc5ed\uc790\uce58\ub2e8\uccb4"] == region)
        row = df_all[cond]
        return int(row["\ud658\uc790\uc218"].values[0]) if not row.empty else None

    except Exception as e:
        st.warning(f"âš ï¸ ì‘ë…„ í™˜ììˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return None

# âœ… ë‚ ì§œ ì„ íƒ ë²”ìœ„ ì„¤ì •
min_pred_date = datetime.date(2025, 7, 1)
max_pred_date = datetime.date(2025, 8, 31)

# âœ… ì§€ì—­ ë° ë‚ ì§œ ì„ íƒ UI
region = st.selectbox("ì§€ì—­ ì„ íƒ", list(region_to_stn_id.keys()), key="region_tab1")
date_selected = st.date_input("ë‚ ì§œ ì„ íƒ", value=min_pred_date, min_value=min_pred_date, max_value=max_pred_date, key="date_tab1")

# âœ… ì˜ˆì¸¡ ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if st.button("ğŸ” ì˜ˆì¸¡í•˜ê¸°", key="predict_tab1"):
    today = datetime.date.today()

    if date_selected >= today:
        weather, base_date, base_time = get_weather(region, date_selected, KMA_API_KEY)
    else:
        ymd = date_selected.strftime("%Y%m%d")
        weather = get_asos_weather(region, ymd, ASOS_API_KEY)

    if not weather:
        st.error("âŒ ê¸°ìƒ ì •ë³´ ì—†ìŒ")
        st.stop()

    tmx = weather.get("TMX", 0)
    tmn = weather.get("TMN", 0)
    reh = weather.get("REH", 0)
    heat_index = compute_heat_index(tmx, reh)

    pred, avg_temp, input_df = predict_from_weather(tmx, tmn, reh)
    risk = get_risk_level(pred)

    with st.expander("ğŸ¤ª ì…ë ¥ê°’ í™•ì¸"):
        st.dataframe(input_df)

    st.markdown("#### ğŸ’¡ ì˜ˆì¸¡ ê²°ê³¼")
    c1, c2 = st.columns(2)
    c1.metric("ì˜ˆì¸¡ í™˜ì ìˆ˜", f"{pred:.2f}ëª…")
    c2.metric("ìœ„í—˜ ë“±ê¸‰", risk)

    last_year_count = get_last_year_patient_count(date_selected, region)
    if last_year_count is not None:
        delta = pred - last_year_count
        st.markdown(f"""
        ğŸ“… **ì „ë…„ë„({(date_selected - datetime.timedelta(days=365)).strftime('%Y-%m-%d')}) ë™ì¼ ë‚ ì§œ í™˜ììˆ˜**: **{last_year_count}ëª…**  
        ğŸ“ˆ **ì „ë…„ ëŒ€ë¹„ ì¦ê°€**: {'+' if delta >= 0 else ''}{delta:.1f}ëª…
        """)
    else:
        st.info("â„¹ï¸ ì „ë…„ë„ ë™ì¼ ë‚ ì§œì˜ í™˜ì ìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    SAVE_FILE = "ML_asos_total_prediction.csv"
    today_str = date_selected.strftime("%Y-%m-%d")

    try:
        df_total = pd.read_csv(SAVE_FILE, encoding="utf-8-sig")
    except FileNotFoundError:
        df_total = pd.DataFrame(columns=["\uc77c\uc790", "\uc11c\uc6b8\uc2dc\uc608\uce21\ud658\uc790\uc218"])

    new_row = pd.DataFrame([{ "\uc77c\uc790": today_str, "\uc11c\uc6b8\uc2dc\uc608\uce21\ud658\uc790\uc218": round(pred, 2) }])
    df_total = pd.concat([df_total, new_row], ignore_index=True)
    df_total.to_csv(SAVE_FILE, index=False, encoding="utf-8-sig")
    st.success(f"âœ… ì˜ˆì¸¡ê°’ì´ '{SAVE_FILE}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    with open(SAVE_FILE, "rb") as f:
        content = f.read()
    b64_content = base64.b64encode(content).decode("utf-8")

    api_url = f"https://api.github.com/repos/{GITHUB_USERNAME}/{GITHUB_REPO}/contents/{SAVE_FILE}"
    r = requests.get(api_url, headers={"Authorization": f"Bearer {GITHUB_TOKEN}"})
    sha = r.json().get("sha") if r.status_code == 200 else None

    payload = {
        "message": f"[tab1] {date_selected} ì˜ˆì¸¡ê°’ ì—…ë°ì´íŠ¸",
        "content": b64_content,
        "branch": GITHUB_BRANCH
    }
    if sha:
        payload["sha"] = sha

    headers = {
        "Authorization": f"Bearer {GITHUB_TOKEN}",
        "Accept": "application/vnd.github+json"
    }
    r = requests.put(api_url, headers=headers, json=payload)

    if r.status_code in [200, 201]:
        st.success("âœ… GitHubì— ì˜ˆì¸¡ê°’ ì €ì¥ ì™„ë£Œ")
        st.info(f"ğŸ”— [GitHubì—ì„œ í™•ì¸í•˜ê¸°](https://github.com/{GITHUB_USERNAME}/{GITHUB_REPO}/blob/{GITHUB_BRANCH}/{SAVE_FILE})")
    else:
        st.warning(f"âš ï¸ GitHub ì €ì¥ ì‹¤íŒ¨: {r.status_code} / {r.text[:200]}")

with tab2:
    # âœ… ì‚¬ìš©ë²• ì•ˆë‚´
    with st.expander("ğŸ“Š tab2ì—ì„œ ì…ë ¥ëœ ì •ë³´ëŠ” ì´ë ‡ê²Œ í™œìš©ë©ë‹ˆë‹¤"):
        st.markdown("""
        1. ì„œìš¸íŠ¹ë³„ì‹œ ê° ìì¹˜êµ¬ì˜ **ì‹¤ì œ í­ì—¼ í”¼í•´ ì—¬ë¶€(1 ë˜ëŠ” 0)**ë¥¼ ìˆ˜ì§‘í•˜ì—¬,  
           **tab3ì˜ í”¼í•´ì ìˆ˜ ê³„ì‚°**ì— í™œìš©ë©ë‹ˆë‹¤.  
           (â€» ì˜¨ì—´ì§ˆí™˜ì ìˆ˜ê°€ **1ëª… ì´ìƒ ë°œìƒí•œ ê²½ìš° â†’ í”¼í•´ ë°œìƒ(1)**ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.)

        2. ì‹¤ì œ ê¸°ìƒì¡°ê±´ê³¼ ì˜¨ì—´ì§ˆí™˜ì ìˆ˜ë¥¼ í•¨ê»˜ ì €ì¥í•˜ì—¬,  
           **tab1ì˜ ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ë°ì´í„°ë¡œ ìë™ ë°˜ì˜**ë©ë‹ˆë‹¤.

        ğŸ“… **ì •í™•í•œ í”¼í•´ íŒë‹¨ì„ ìœ„í•´ ì˜¤ëŠ˜ ë‚ ì§œëŠ” ì œì™¸ë˜ë©°, ì–´ì œê¹Œì§€ì˜ ì •ë³´ë§Œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**  
        ì´ëŠ” ì§ˆë³‘ê´€ë¦¬ì²­ì˜ ì˜¨ì—´ì§ˆí™˜ì í†µê³„ê°€ **í•˜ë£¨ ë‹¨ìœ„ë¡œ ì§‘ê³„ë˜ì–´ ìµì¼ì— ê³µê°œ**ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

        ğŸ“‚ ì•„ë˜ ë§í¬ì—ì„œ ì§ˆë³‘ì²­ì˜ ì˜¨ì—´ì§ˆí™˜ì ì—‘ì…€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.  
        ğŸ‘‰ [ì˜¨ì—´ì§ˆí™˜ ì‘ê¸‰ì‹¤ê°ì‹œì²´ê³„ ë‹¤ìš´ë¡œë“œ](https://www.kdca.go.kr/board/board.es?mid=a20205030102&bid=0004&&cg_code=C01)

        âœ… ëª¨ë“  ì…ë ¥ì´ ì™„ë£Œë˜ë©´ **ì €ì¥í•˜ê¸°** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.  
        ì…ë ¥ëœ ë°ì´í„°ëŠ” ìë™ìœ¼ë¡œ ë‚´ë¶€ DBì— ê¸°ë¡ë˜ì–´ ë‹¤ë¥¸ íƒ­ì—ì„œ ì¦‰ì‹œ í™œìš©ë©ë‹ˆë‹¤.
        """)

    region = st.selectbox("ğŸŒ ê´‘ì—­ì‹œë„ ì„ íƒ", ["ì„œìš¸íŠ¹ë³„ì‹œ"], key="region_tab2")

    all_gus = [
        'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬', 'ê´‘ì§„êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬', 'ì„±ë¶êµ¬', 'ê°•ë¶êµ¬', 'ë„ë´‰êµ¬',
        'ë…¸ì›êµ¬', 'ì€í‰êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ë§ˆí¬êµ¬', 'ì–‘ì²œêµ¬', 'ê°•ì„œêµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ì˜ë“±í¬êµ¬',
        'ë™ì‘êµ¬', 'ê´€ì•…êµ¬', 'ì„œì´ˆêµ¬', 'ê°•ë‚¨êµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬'
    ]
    gus = st.multiselect("ğŸ˜ï¸ ìì¹˜êµ¬ ì„ íƒ (ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´)", all_gus, key="gu_tab2_multi")
    if not gus:
        gus = all_gus

    min_record_date = datetime.date(2025, 7, 1)
    max_record_date = datetime.date.today() - datetime.timedelta(days=1)

    date_selected = st.date_input(
        "ğŸ“… ì €ì¥í•  ë‚ ì§œ ì„ íƒ", 
        value=max_record_date, 
        min_value=min_record_date, 
        max_value=max_record_date,
        key="date_tab2"
    )

    uploaded_file = st.file_uploader("ğŸ“ ì§ˆë³‘ì²­ í™˜ììˆ˜ íŒŒì¼ ì—…ë¡œë“œ (.xlsx, ì‹œíŠ¸ëª…: ì„œìš¸íŠ¹ë³„ì‹œ)", type=["xlsx"], key="upload_tab2")

    if uploaded_file and date_selected:
        try:
            df_raw = pd.read_excel(uploaded_file, sheet_name="ì„œìš¸íŠ¹ë³„ì‹œ", header=None)
            districts = df_raw.iloc[0, 1::2].tolist()
            dates = df_raw.iloc[3:, 0].tolist()
            df_values = df_raw.iloc[3:, 1::2]
            df_values.columns = districts
            df_values.insert(0, "ì¼ì", dates)
            df_long = df_values.melt(id_vars=["ì¼ì"], var_name="ìì¹˜êµ¬", value_name="í™˜ììˆ˜")
            df_long["ì¼ì"] = pd.to_datetime(df_long["ì¼ì"], errors="coerce").dt.strftime("%Y-%m-%d")
            df_long["í™˜ììˆ˜"] = pd.to_numeric(df_long["í™˜ììˆ˜"], errors="coerce").fillna(0).astype(int)
            df_long["ì§€ì—­"] = "ì„œìš¸íŠ¹ë³„ì‹œ"

            preview_list = []
            ymd = date_selected.strftime("%Y-%m-%d")

            weather = get_asos_weather(region, ymd.replace("-", ""), ASOS_API_KEY)
            tmx = weather.get("TMX", 0)
            tmn = weather.get("TMN", 0)
            reh = weather.get("REH", 0)
            avg_temp = calculate_avg_temp(tmx, tmn)
            heat_index = compute_heat_index(tmx, reh)

            for gu in gus:
                selected = df_long[(df_long["ì¼ì"] == ymd) & (df_long["ìì¹˜êµ¬"] == gu)]
                if selected.empty:
                    st.warning(f"âŒ {ymd} {gu} í™˜ììˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                í™˜ììˆ˜ = int(selected["í™˜ììˆ˜"].values[0])
                preview_list.append({
                    "ì¼ì": ymd,
                    "ì§€ì—­": region,
                    "ìì¹˜êµ¬": gu,
                    "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)": heat_index,
                    "ìµœê³ ê¸°ì˜¨(Â°C)": tmx,
                    "í‰ê· ê¸°ì˜¨(Â°C)": avg_temp,
                    "ìµœì €ê¸°ì˜¨(Â°C)": tmn,
                    "í‰ê· ìƒëŒ€ìŠµë„(%)": reh,
                    "í™˜ììˆ˜": í™˜ììˆ˜
                })

            if not preview_list:
                st.warning("âŒ ì„ íƒí•œ ë‚ ì§œì™€ ìì¹˜êµ¬ ì¡°í•©ì— ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

            preview_df = pd.DataFrame(preview_list)
            st.markdown("#### âœ… ì €ì¥ë  í•™ìŠµ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(preview_df)

            if st.button("ğŸ’¾ GitHubì— ì €ì¥í•˜ê³  ëª¨ë¸ ì¬í•™ìŠµí•˜ê¸°", key="save_and_train_tab2"):
                csv_path = "ML_asos_dataset.csv"

                if os.path.exists(csv_path):
                    try:
                        existing = pd.read_csv(csv_path, encoding="utf-8-sig")
                    except UnicodeDecodeError:
                        existing = pd.read_csv(csv_path, encoding="cp949")
                else:
                    existing = pd.DataFrame()

                merge_keys = ["ì¼ì", "ìì¹˜êµ¬"]
                if not existing.empty:
                    existing = existing[~existing.set_index(merge_keys).index.isin(preview_df.set_index(merge_keys).index)]
                df_all = pd.concat([existing, preview_df], ignore_index=True)
                df_all.to_csv(csv_path, index=False, encoding="utf-8-sig")
                st.success("âœ… í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ (ë¡œì»¬)")

                try:
                    with open(csv_path, "rb") as f:
                        content = f.read()
                    b64_content = base64.b64encode(content).decode("utf-8")

                    api_url = f"https://api.github.com/repos/{GITHUB_USERNAME}/{GITHUB_REPO}/contents/{GITHUB_FILENAME}"
                    r = requests.get(api_url, headers={"Authorization": f"Bearer {GITHUB_TOKEN}"})
                    sha = r.json().get("sha") if r.status_code == 200 else None

                    payload = {
                        "message": f"Update {GITHUB_FILENAME} with new data for {region} ({len(preview_list)} entries)",
                        "content": b64_content,
                        "branch": GITHUB_BRANCH
                    }
                    if sha:
                        payload["sha"] = sha

                    headers = {
                        "Authorization": f"Bearer {GITHUB_TOKEN}",
                        "Accept": "application/vnd.github+json"
                    }
                    r = requests.put(api_url, headers=headers, json=payload)
                    if r.status_code in [200, 201]:
                        st.success("âœ… GitHub ì €ì¥ ì™„ë£Œ")
                        st.info(f"ğŸ”— [GitHubì—ì„œ ë³´ê¸°](https://github.com/{GITHUB_USERNAME}/{GITHUB_REPO}/blob/{GITHUB_BRANCH}/{GITHUB_FILENAME})")
                    else:
                        st.warning(f"âš ï¸ GitHub ì €ì¥ ì‹¤íŒ¨: {r.status_code} {r.text[:200]}")

                except Exception as e:
                    st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.stop()

                st.info("ğŸ“ˆ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì¬í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤...")
                try:
                    result = subprocess.run([sys.executable, "train_model.py"], capture_output=True, text=True, check=True)
                    st.success("âœ… ëª¨ë¸ ì¬í•™ìŠµ ì™„ë£Œ")
                    st.text_area("ğŸ“„ í•™ìŠµ ë¡œê·¸", result.stdout, height=300)
                except subprocess.CalledProcessError as e:
                    st.error("âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
                    st.text_area("ğŸš¨ ì˜¤ë¥˜ ë¡œê·¸", e.stderr or str(e), height=300)

        except Exception as e:
            st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

with tab3:
    # âœ… ì‚¬ìš©ë²• ì•ˆë‚´
    with st.expander("ğŸ“Š tab3ì—ì„œ ì‚°ì¶œëœ ì •ë³´ëŠ” ì´ë ‡ê²Œ í™œìš©ë©ë‹ˆë‹¤"):
        st.markdown("""
        1. tab1ì—ì„œ ì˜ˆì¸¡í•œ **ê´‘ì—­ì‹œë„ë³„ ì˜¨ì—´ì§ˆí™˜ì ìˆ˜**ë¥¼ ìì¹˜êµ¬ë³„ **ì‚¬íšŒì  ì·¨ì•½ì„±(S)**ì—    
           ë”°ë¼ ë¶„ë°°í•˜ê³ , ì •ê·œí™”í•˜ì—¬ ìì¹˜êµ¬ë³„ **ì˜ˆì¸¡ í™˜ììˆ˜(P_pred)**ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        2. tab2ì—ì„œ ìˆ˜ì§‘ëœ **ì‹¤ì œ ì˜¨ì—´ì§ˆí™˜ì ìˆ˜(P_real)**,  
           ê·¸ë¦¬ê³  ìì¹˜êµ¬ë³„ **ì‚¬íšŒì (S)** ë° **í™˜ê²½ì (E)** ì·¨ì•½ì„± ì§€í‘œì™€ í•¨ê»˜  
           **ì¢…í•©ì ì¸ í”¼í•´ì ìˆ˜(0~100ì )**ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        3. í”¼í•´ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ í•´ë‹¹ ìì¹˜êµ¬ê°€ ë” í° í­ì—¼ í”¼í•´ ìœ„í—˜ì— ë…¸ì¶œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼ë˜ë©°,  
           ìœ„í—˜ë“±ê¸‰(ğŸŸ¢~ğŸ”¥)ê³¼ **ë³´ìƒê¸ˆ ì‚°ì • ê¸°ì¤€**ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

        ğŸ“Œ í”¼í•´ì ìˆ˜ ê³„ì‚°ì€ ë‹¤ìŒ ìš”ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤:
        - ğŸ§“ S: ê³ ë ¹ì ë¹„ìœ¨, ì•¼ì™¸ ê·¼ë¡œì ë¹„ìœ¨, ì—´ì·¨ì•½ ì¸êµ¬ ë¹„ìœ¨  
        - ğŸŒ E: ì—´ì„¬ì§€ìˆ˜, ë…¹ì§€ìœ¨, ëƒ‰ë°©ë³´ê¸‰ë¥  (í‘œì¤€í™”ëœ í™˜ê²½ì§€í‘œ)  
        - ğŸ“ˆ P_pred: AI ì˜ˆì¸¡ í™˜ì ìˆ˜ (ìì¹˜êµ¬ë³„ ë¶„ë°° ë° ì •ê·œí™”)  
        - ğŸ“‰ P_real: ì‹¤ì œ í™˜ì ìˆ˜ (1ëª… ì´ìƒì´ë©´ 1.0, ì—†ìœ¼ë©´ 0.0)

        í”¼í•´ì ìˆ˜ = 100 Ã— (0.2 Ã— S + 0.2 Ã— E + 0.5 Ã— P_pred + 0.1 Ã— P_real)
        """)

    # âœ… í•¨ìˆ˜ ì •ì˜
    def format_debug_log(row, date_str):
        return f"""[í”¼í•´ì ìˆ˜ ê³„ì‚° ë¡œê·¸ - {row['ìì¹˜êµ¬']} / {date_str}]
[S ê³„ì‚°] - ê³ ë ¹ìë¹„ìœ¨ = {row['ê³ ë ¹ìë¹„ìœ¨']:.4f}, ì•¼ì™¸ê·¼ë¡œìë¹„ìœ¨ = {row['ì•¼ì™¸ê·¼ë¡œìë¹„ìœ¨']:.4f}, ì—´ì·¨ì•½ì¸êµ¬ë¹„ìœ¨ = {row['ì—´ì¾Œì ì·¨ì•½ì¸êµ¬ë¹„ìœ¨']:.4f} â†’ S = {row['S']:.4f}
[E ê³„ì‚°] - ì—´ì„¬ì§€ìˆ˜ = {row['ì—´ì„¬ì§€ìˆ˜_std']:.4f}, ë…¹ì§€ìœ¨ = {row['ë…¹ì§€ìœ¨_std']:.4f}, ëƒ‰ë°©ë³´ê¸‰ë¥  = {row['ëƒ‰ë°©ë³´ê¸‰ë¥ _std']:.4f} â†’ E = {row['E']:.4f}
[P ê³„ì‚°] - ì˜ˆì¸¡í™˜ììˆ˜ = {row['P_pred_raw']:.2f}ëª… â†’ ì •ê·œí™”(P_pred) = {row['P_pred']:.4f}
[R ê³„ì‚°] - ì‹¤ì œí™˜ììˆ˜ = {row['í™˜ììˆ˜']}, ë³€í™˜(P_real) = {1.0 if row['í™˜ììˆ˜'] >= 1 else 0.0}
ğŸ§® í”¼í•´ì ìˆ˜ = {row['í”¼í•´ì ìˆ˜']:.2f} / ìœ„í—˜ë“±ê¸‰: {row['ìœ„í—˜ë“±ê¸‰']} / ë³´ìƒê¸ˆ: {row['ë³´ìƒê¸ˆ']}ì›
"""

    def calculate_social_index(row):
        return (
            0.5 * row["ê³ ë ¹ìë¹„ìœ¨"] +
            0.3 * row["ì•¼ì™¸ê·¼ë¡œìë¹„ìœ¨"] +
            0.2 * row["ì—´ì¾Œì ì·¨ì•½ì¸êµ¬ë¹„ìœ¨"]
        )

    def standardize_column(df, col):
        min_val = df[col].min()
        max_val = df[col].max()
        range_val = max_val - min_val if max_val != min_val else 1
        return (df[col] - min_val) / range_val

    def calculate_environment_index(row):
        return (
            0.5 * row["ì—´ì„¬ì§€ìˆ˜_std"] +
            0.3 * (1 - row["ë…¹ì§€ìœ¨_std"]) +
            0.2 * (1 - row["ëƒ‰ë°©ë³´ê¸‰ë¥ _std"])
        )

    def distribute_pred_by_s(merged_df, total_pred):
        """
        S ë¹„ìœ¨ì— ë”°ë¼ ìì¹˜êµ¬ë³„ ì˜ˆì¸¡í™˜ììˆ˜ ë¶„ë°° ë° âˆš ì •ê·œí™”
        (25ëª…ì€ ì„œìš¸ì‹œ í•˜ë£¨ ìµœëŒ€ ì˜ˆì¸¡ í™˜ììˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”ì— ì‚¬ìš©ë¨)
        """
        s_sum = merged_df["S"].sum()
        merged_df["P_pred_raw"] = total_pred * (merged_df["S"] / s_sum)
        merged_df["P_pred"] = (merged_df["P_pred_raw"] / 25) ** 0.5
        return merged_df

    def calculate_damage_score_v2(s, e, p_pred, p_real):
        return 100 * (0.2 * s + 0.2 * e + 0.5 * p_pred + 0.1 * p_real)

    def score_to_grade(score):
        if score < 20: return "ğŸŸ¢ ë§¤ìš° ë‚®ìŒ"
        elif score < 30: return "ğŸŸ¡ ë‚®ìŒ"
        elif score < 40: return "ğŸŸ  ë³´í†µ"
        elif score < 50: return "ğŸ”´ ë†’ìŒ"
        else: return "ğŸ”¥ ë§¤ìš° ë†’ìŒ"

    def calc_payout(score):
        if score < 30: return 0
        elif score < 40: return 5000
        elif score < 50: return 10000
        else: return 20000

    def load_csv_with_fallback(path):
        for enc in ["utf-8-sig", "cp949", "euc-kr"]:
            try:
                return pd.read_csv(path, encoding=enc)
            except UnicodeDecodeError:
                continue
        raise UnicodeDecodeError(f"âŒ ì¸ì½”ë”© ì‹¤íŒ¨: {path}")

    def load_csv_from_github(filename):
        try:
            github_url =   f"https://raw.githubusercontent.com/{GITHUB_USERNAME}/{GITHUB_REPO}/{GITHUB_BRANCH}/{filename}"
            r = requests.get(github_url)
            r.raise_for_status()
            return pd.read_csv(io.StringIO(r.text), encoding="utf-8-sig")
        except Exception as e:
            st.error(f"âŒ GitHubì—ì„œ {filename} ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return pd.DataFrame()


    # âœ… ë©”ì¸ ì‹¤í–‰
    try:
        col1, col2 = st.columns(2)
        with col1:
            selected_date = st.date_input("ğŸ“… ë¶„ì„ ë‚ ì§œ ì„ íƒ", datetime.date.today())
            ymd = selected_date.strftime("%Y-%m-%d")
        with col2:
            selected_gu = None

        ml_data = load_csv_from_github("ML_asos_dataset.csv")
        if ml_data.empty:
            st.warning("â—ï¸ê¸°ë¡ëœ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. tab2ì—ì„œ ë°ì´í„°ë¥¼ ë¨¼ì € ì €ì¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        ml_data = ml_data[ml_data["ì¼ì"] == ymd]
        static_data = load_csv_with_fallback("seoul_static_data.csv")
        merged_all = pd.merge(static_data, ml_data, on="ìì¹˜êµ¬", how="left")

        if merged_all.empty:
            st.warning("â—ï¸ì„ íƒí•œ ë‚ ì§œì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        df_total = load_csv_from_github("ML_asos_total_prediction.csv")
        pred_row = df_total[df_total["ì¼ì"] == ymd]

        if pred_row.empty:
            st.warning(f"âš ï¸ {ymd} ì˜ˆì¸¡ê°’ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. tab1ì—ì„œ ë¨¼ì € ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
            st.stop()

        seoul_pred = float(pred_row["ì„œìš¸ì‹œì˜ˆì¸¡í™˜ììˆ˜"].values[0])

        merged_all["S"] = merged_all.apply(calculate_social_index, axis=1)
        for col in ["ì—´ì„¬ì§€ìˆ˜", "ë…¹ì§€ìœ¨", "ëƒ‰ë°©ë³´ê¸‰ë¥ "]:
            merged_all[f"{col}_std"] = standardize_column(merged_all, col)
        merged_all["E"] = merged_all.apply(calculate_environment_index, axis=1)

        merged_all = distribute_pred_by_s(merged_all, seoul_pred)

        merged_all["í”¼í•´ì ìˆ˜"] = merged_all.apply(
            lambda row: calculate_damage_score_v2(
                row["S"], row["E"], row["P_pred"], 1.0 if row["í™˜ììˆ˜"] >= 1 else 0.0
            ),
            axis=1
        )
        merged_all["ìœ„í—˜ë“±ê¸‰"] = merged_all["í”¼í•´ì ìˆ˜"].apply(score_to_grade)
        merged_all["ë³´ìƒê¸ˆ"] = merged_all["í”¼í•´ì ìˆ˜"].apply(calc_payout)

        col1, col2 = st.columns(2)
        with col1:
            selected_gu = st.selectbox("ğŸ˜ï¸ ìì¹˜êµ¬ ì„ íƒ", sorted(merged_all["ìì¹˜êµ¬"].unique()))
        with col2:
            subs_count = st.number_input(f"{selected_gu} ê°€ì…ì ìˆ˜", min_value=0, step=1, key="subs_tab3")

        merged = merged_all[merged_all["ìì¹˜êµ¬"] == selected_gu].copy()
        if merged.empty:
            st.warning("ì„ íƒí•œ ìì¹˜êµ¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        merged["ê°€ì…ììˆ˜"] = subs_count
        merged["ì˜ˆìƒì´ë³´ìƒê¸ˆ"] = merged["ë³´ìƒê¸ˆ"] * subs_count
        st.success(f"ğŸ’° ì˜ˆìƒ ë³´ìƒê¸ˆì•¡: {int(merged['ì˜ˆìƒì´ë³´ìƒê¸ˆ'].sum()):,}ì›")

        show_cols = ["ìì¹˜êµ¬", "í”¼í•´ì ìˆ˜", "ìœ„í—˜ë“±ê¸‰", "ë³´ìƒê¸ˆ", "ê°€ì…ììˆ˜", "ì˜ˆìƒì´ë³´ìƒê¸ˆ"]
        st.dataframe(merged[show_cols], use_container_width=True)

        st.markdown("#### ğŸ“Š í”¼í•´ì ìˆ˜ ë¶„í¬")
        st.bar_chart(data=merged_all.set_index("ìì¹˜êµ¬")["í”¼í•´ì ìˆ˜"])

        # âœ… ë‹¨ì¼ ìì¹˜êµ¬ ë””ë²„ê¹… ë¡œê·¸
        row = merged.iloc[0]
        single_log = format_debug_log(row, ymd)

        with st.expander(f"ğŸ” {selected_gu} ë””ë²„ê¹… ë¡œê·¸"):
            st.code(single_log, language="text")
            st.download_button(
                label="ğŸ“„ í˜„ì¬ ìì¹˜êµ¬ ë””ë²„ê¹… ë¡œê·¸ ë‹¤ìš´ë¡œë“œ",
                data=single_log.encode("utf-8-sig"),
                file_name=f"í”¼í•´ì ìˆ˜_ë””ë²„ê¹…_{ymd}_{selected_gu}.txt",
                mime="text/plain"
            )

        # âœ… ì „ì²´ ìì¹˜êµ¬ ë””ë²„ê¹… ë¡œê·¸
        all_debug_logs = "\n".join([
            format_debug_log(row, ymd) for _, row in merged_all.iterrows()
        ])
        st.download_button(
            label="ğŸ“¥ ì „ì²´ ìì¹˜êµ¬ ë””ë²„ê¹… ë¡œê·¸ ë‹¤ìš´ë¡œë“œ",
            data=all_debug_logs.encode("utf-8-sig"),
            file_name=f"ì „ì²´_í”¼í•´ì ìˆ˜_ë””ë²„ê¹…_{ymd}.txt",
            mime="text/plain"
        )

    except Exception as e:
        st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

