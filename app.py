import streamlit as st
import pandas as pd
import datetime
import requests
import os
import base64
from urllib.parse import unquote

from utils import (
    get_weather, get_asos_weather, get_risk_level,
    calculate_avg_temp, region_to_stn_id
)
from model_utils import predict_from_weather

# ----------------------- ğŸ“¦ ì„¤ì • -----------------------
st.set_page_config(layout="centered")

KMA_API_KEY = unquote(st.secrets["KMA"]["API_KEY"])
ASOS_API_KEY = unquote(st.secrets["ASOS"]["API_KEY"])
GITHUB_USERNAME = st.secrets["GITHUB"]["USERNAME"]
GITHUB_REPO = st.secrets["GITHUB"]["REPO"]
GITHUB_BRANCH = st.secrets["GITHUB"]["BRANCH"]
GITHUB_TOKEN = st.secrets["GITHUB"]["TOKEN"]
GITHUB_FILENAME = "ML_asos_dataset.csv"

# ----------------------- ğŸ§­ UI ì‹œì‘ -----------------------
st.title("HeatAI")
tab1, tab2, tab3 = st.tabs(["ğŸ“Š í­ì—¼íŠ¸ë¦¬ê±° ì˜ˆì¸¡í•˜ê¸°", "ğŸ“¥ AI í•™ìŠµ ë°ì´í„° ì¶”ê°€", "ğŸ“ ìì¹˜êµ¬ í”¼í•´ì ìˆ˜ ë¶„ì„"])

# ====================================================================
# ğŸ”® ì˜ˆì¸¡ íƒ­
# ====================================================================
with tab1:
    st.header("ğŸ“Š í­ì—¼íŠ¸ë¦¬ê±° ì˜ˆì¸¡í•˜ê¸°")

    today = datetime.date.today()
    min_pred_date = today
    max_pred_date = today + datetime.timedelta(days=4)

    region = st.selectbox("ì§€ì—­ ì„ íƒ", list(region_to_stn_id.keys()), key="region_tab1")
    date_selected = st.date_input("ë‚ ì§œ ì„ íƒ", value=today, min_value=min_pred_date, max_value=max_pred_date, key="date_tab1")

    if st.button("ğŸ” ì˜ˆì¸¡í•˜ê¸°", key="predict_tab1"):
        if date_selected >= today:
            weather, base_date, base_time = get_weather(region, date_selected, KMA_API_KEY)
        else:
            ymd = date_selected.strftime("%Y%m%d")
            weather = get_asos_weather(region, ymd, ASOS_API_KEY)

        if not weather:
            st.error("âŒ ê¸°ìƒ ì •ë³´ ì—†ìŒ")
            st.stop()

        tmx, tmn, reh = weather.get("TMX", 0), weather.get("TMN", 0), weather.get("REH", 0)
        pred, avg_temp, input_df = predict_from_weather(tmx, tmn, reh)
        risk = get_risk_level(pred)

        st.markdown("#### â˜ï¸ ê¸°ìƒì •ë³´")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ìµœê³ ê¸°ì˜¨", f"{tmx:.1f}â„ƒ")
        col2.metric("ìµœì €ê¸°ì˜¨", f"{tmn:.1f}â„ƒ")
        col3.metric("í‰ê· ê¸°ì˜¨", f"{avg_temp:.1f}â„ƒ")
        col4.metric("ìŠµë„", f"{reh:.1f}%")

        with st.expander("ğŸ§ª ì…ë ¥ê°’ í™•ì¸"):
            st.dataframe(input_df)

        st.markdown("#### ğŸ’¡ ì˜ˆì¸¡ ê²°ê³¼")
        c1, c2 = st.columns(2)
        c1.metric("ì˜ˆì¸¡ í™˜ì ìˆ˜", f"{pred:.2f}ëª…")
        c2.metric("ìœ„í—˜ ë“±ê¸‰", risk)

        def get_last_year_patient_count(current_date, region, static_file="ML_7_8ì›”_2021_2025_dataset.xlsx"):
            try:
                last_year_date = current_date - datetime.timedelta(days=365)
                df_all = pd.read_excel(static_file, engine="openpyxl")
                df_all["ì¼ì‹œ"] = pd.to_datetime("1899-12-30") + pd.to_timedelta(df_all["ì¼ì‹œ"], unit="D")
                df_all["ì¼ì"] = df_all["ì¼ì‹œ"].dt.strftime("%Y-%m-%d")
                cond = (df_all["ì¼ì"] == last_year_date.strftime("%Y-%m-%d")) & (df_all["ê´‘ì—­ìì¹˜ë‹¨ì²´"] == region)
                row = df_all[cond]
                if not row.empty:
                    return int(row["í™˜ììˆ˜"].values[0])
                else:
                    return None
            except:
                return None

        last_year_count = get_last_year_patient_count(date_selected, region)
        if last_year_count is not None:
            delta = pred - last_year_count
            st.markdown(f"ğŸ“… **ì „ë…„ë„({(date_selected - datetime.timedelta(days=365)).strftime('%Y-%m-%d')}) ë™ì¼ ë‚ ì§œ í™˜ììˆ˜**: **{last_year_count}ëª…**")
            st.markdown(f"ğŸ“ˆ **ì „ë…„ ëŒ€ë¹„ ì¦ê°**: {'+' if delta >= 0 else ''}{delta:.1f}ëª…")
        else:
            st.markdown("ğŸ“­ ì „ë…„ë„ ë™ì¼ ë‚ ì§œì˜ í™˜ì ìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ====================================================================
# ğŸ“¥ AI í•™ìŠµ ë°ì´í„° ì¶”ê°€
# ====================================================================
with tab2:
    with st.expander("â„¹ï¸ tab2 ì‚¬ìš©ë²•"):
        st.markdown("""
        **âœ… ì‚¬ìš© ë°©ë²•**  
        1. ë‚ ì§œ(ë³µìˆ˜ ê°€ëŠ¥)ì™€ ìì¹˜êµ¬(ì „ì²´ ë˜ëŠ” ì¼ë¶€)ë¥¼ ì„ íƒí•˜ì„¸ìš”.  
        2. ì•„ë˜ ë§í¬ì—ì„œ ì§ˆë³‘ì²­ì˜ ì˜¨ì—´ì§ˆí™˜ì ì—‘ì…€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ ì—…ë¡œë“œí•˜ì„¸ìš”.  
           ğŸ‘‰ [ì˜¨ì—´ì§ˆí™˜ ì‘ê¸‰ì‹¤ê°ì‹œì²´ê³„ ë‹¤ìš´ë¡œë“œ](https://www.kdca.go.kr/board/board.es?mid=a20205030102&bid=0004&&cg_code=C01)  
        3. **ì €ì¥í•˜ê¸°** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´, í•´ë‹¹ ë°ì´í„°ëŠ” tab3ì˜ ìì¹˜êµ¬ë³„ í”¼í•´ì ìˆ˜ ì‚°ì •ì„ ìœ„í•œ ì…ë ¥ê°’ìœ¼ë¡œ ìë™ ë°˜ì˜ë©ë‹ˆë‹¤.
        """)

    st.header("ğŸ“¥ ìì¹˜êµ¬ë³„ ì‹¤ì œ í­ì—¼ ë°ì´í„° ì €ì¥í•˜ê¸°")

    region = st.selectbox("ğŸŒ ê´‘ì—­ì‹œë„ ì„ íƒ", ["ì„œìš¸íŠ¹ë³„ì‹œ"], key="region_tab2")

    all_gus = [
        'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬', 'ê´‘ì§„êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬', 'ì„±ë¶êµ¬', 'ê°•ë¶êµ¬', 'ë„ë´‰êµ¬',
        'ë…¸ì›êµ¬', 'ì€í‰êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ë§ˆí¬êµ¬', 'ì–‘ì²œêµ¬', 'ê°•ì„œêµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ì˜ë“±í¬êµ¬',
        'ë™ì‘êµ¬', 'ê´€ì•…êµ¬', 'ì„œì´ˆêµ¬', 'ê°•ë‚¨êµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬'
    ]

    gus = st.multiselect("ğŸ˜ï¸ ìì¹˜êµ¬ ì„ íƒ (ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´)", all_gus, key="gu_tab2_multi")
    if not gus:
        gus = all_gus

    # âœ… ë‚ ì§œ ì„ íƒ: pandas â†’ date ë³€í™˜
    min_record_date = datetime.date(2021, 5, 1)
    max_record_date = datetime.date.today() - datetime.timedelta(days=1)
    date_range = [d.date() for d in pd.date_range(min_record_date, max_record_date, freq='D')]

    dates_selected = st.multiselect("ğŸ“… ê¸°ë¡í•  ë‚ ì§œ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", date_range, default=[max_record_date])

    uploaded_file = st.file_uploader("ğŸ“ ì§ˆë³‘ì²­ í™˜ììˆ˜ íŒŒì¼ ì—…ë¡œë“œ (.xlsx, ì‹œíŠ¸ëª…: ì„œìš¸íŠ¹ë³„ì‹œ)", type=["xlsx"], key="upload_tab2")

    if uploaded_file and dates_selected:
        try:
            df_raw = pd.read_excel(uploaded_file, sheet_name="ì„œìš¸íŠ¹ë³„ì‹œ", header=None)
            districts = df_raw.iloc[0, 1::2].tolist()
            dates = df_raw.iloc[3:, 0].tolist()
            df_values = df_raw.iloc[3:, 1::2]
            df_values.columns = districts
            df_values.insert(0, "ì¼ì", dates)
            df_long = df_values.melt(id_vars=["ì¼ì"], var_name="ìì¹˜êµ¬", value_name="í™˜ììˆ˜")
            df_long["ì¼ì"] = pd.to_datetime(df_long["ì¼ì"], errors="coerce").dt.strftime("%Y-%m-%d")
            df_long["í™˜ììˆ˜"] = pd.to_numeric(df_long["í™˜ììˆ˜"], errors="coerce").fillna(0).astype(int)
            df_long["ì§€ì—­"] = "ì„œìš¸íŠ¹ë³„ì‹œ"

            preview_list = []

            for date_selected in dates_selected:
                ymd = date_selected.strftime("%Y-%m-%d")

                weather = get_asos_weather(region, ymd.replace("-", ""), ASOS_API_KEY)
                tmx = weather.get("TMX", 0)
                tmn = weather.get("TMN", 0)
                reh = weather.get("REH", 0)
                avg_temp = calculate_avg_temp(tmx, tmn)

                for gu in gus:
                    selected = df_long[(df_long["ì¼ì"] == ymd) & (df_long["ìì¹˜êµ¬"] == gu)]
                    if selected.empty:
                        st.warning(f"âŒ {ymd} {gu} í™˜ììˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        continue

                    í™˜ììˆ˜ = int(selected["í™˜ììˆ˜"].values[0])
                    preview_list.append({
                        "ì¼ì": ymd,
                        "ì§€ì—­": region,
                        "ìì¹˜êµ¬": gu,
                        "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)": tmx + 1.5,
                        "ìµœê³ ê¸°ì˜¨(Â°C)": tmx,
                        "í‰ê· ê¸°ì˜¨(Â°C)": avg_temp,
                        "ìµœì €ê¸°ì˜¨(Â°C)": tmn,
                        "í‰ê· ìƒëŒ€ìŠµë„(%)": reh,
                        "í™˜ììˆ˜": í™˜ììˆ˜
                    })

            if not preview_list:
                st.warning("âŒ ì„ íƒí•œ ë‚ ì§œì™€ ìì¹˜êµ¬ ì¡°í•©ì— ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

            preview_df = pd.DataFrame(preview_list)
            st.markdown("### âœ… ì €ì¥ë  í•™ìŠµ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(preview_df)

            if st.button("ğŸ’¾ GitHubì— ì €ì¥í•˜ê¸°", key="save_tab2_multi"):
                csv_path = "ML_asos_dataset_by_gu.csv"
                if os.path.exists(csv_path):
                    try:
                        existing = pd.read_csv(csv_path, encoding="utf-8-sig")
                    except UnicodeDecodeError:
                        existing = pd.read_csv(csv_path, encoding="cp949")
                    for row in preview_list:
                        existing = existing[~((existing["ì¼ì"] == row["ì¼ì"]) & (existing["ìì¹˜êµ¬"] == row["ìì¹˜êµ¬"]))]
                    df_all = pd.concat([existing, preview_df], ignore_index=True)
                else:
                    df_all = preview_df

                df_all.to_csv(csv_path, index=False, encoding="utf-8-sig")

                with open(csv_path, "rb") as f:
                    content = f.read()
                b64_content = base64.b64encode(content).decode("utf-8")

                api_url = f"https://api.github.com/repos/{GITHUB_USERNAME}/{GITHUB_REPO}/contents/{GITHUB_FILENAME}"
                r = requests.get(api_url, headers={"Authorization": f"Bearer {GITHUB_TOKEN}"})
                sha = r.json().get("sha") if r.status_code == 200 else None

                payload = {
                    "message": f"Update {GITHUB_FILENAME} with new data for {region} ({len(preview_list)} entries)",
                    "content": b64_content,
                    "branch": GITHUB_BRANCH
                }
                if sha:
                    payload["sha"] = sha

                headers = {
                    "Authorization": f"Bearer {GITHUB_TOKEN}",
                    "Accept": "application/vnd.github+json"
                }
                r = requests.put(api_url, headers=headers, json=payload)
                if r.status_code in [200, 201]:
                    st.success("âœ… GitHub ì €ì¥ ì™„ë£Œ")
                    st.info(f"ğŸ”— [GitHubì—ì„œ ë³´ê¸°](https://github.com/{GITHUB_USERNAME}/{GITHUB_REPO}/blob/{GITHUB_BRANCH}/{GITHUB_FILENAME})")
                else:
                    st.warning(f"âš ï¸ GitHub ì €ì¥ ì‹¤íŒ¨: {r.status_code} {r.text[:200]}")

        except Exception as e:
            st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

with tab3:
    st.header("ğŸ“ ìì¹˜êµ¬ë³„ í”¼í•´ì ìˆ˜ ë° ë³´ìƒ ì‚°ì •")

    try:
        # âœ… ë‚ ì§œ ì„ íƒ
        selected_date = st.date_input("ğŸ“… ë¶„ì„ ë‚ ì§œ ì„ íƒ", datetime.date.today())
        ymd = selected_date.strftime("%Y-%m-%d")

        # âœ… ë°ì´í„° ë¡œë“œ
        ml_data = pd.read_csv("ML_asos_dataset.csv", encoding="utf-8-sig")
        static_data = pd.read_csv("seoul_static_data.csv", encoding="utf-8-sig")

        # âœ… ìì¹˜êµ¬ ë³‘í•© ë° í•„í„°ë§
        merged = pd.merge(ml_data, static_data, on="ìì¹˜êµ¬", how="left")
        merged = merged[merged["ì¼ì"] == ymd].copy()

        selected_gu = st.selectbox("ğŸ˜ï¸ ìì¹˜êµ¬ ì„ íƒ", sorted(merged["ìì¹˜êµ¬"].unique()))
        merged = merged[merged["ìì¹˜êµ¬"] == selected_gu].copy()

        # âœ… ì‚¬íšŒì  ì·¨ì•½ì„± ì§€ìˆ˜ S ê³„ì‚°
        merged["S"] = 0.5 * merged["ê³ ë ¹ìë¹„ìœ¨"].fillna(0) + \
                      0.3 * merged["ì•¼ì™¸ê·¼ë¡œìë¹„ìœ¨"].fillna(0) + \
                      0.2 * merged["ì—´ì¾Œì ì·¨ì•½ì¸êµ¬ë¹„ìœ¨"].fillna(0)

        # âœ… í™˜ê²½ì  ì·¨ì•½ì„± ì§€ìˆ˜ E ê³„ì‚° (í‘œì¤€í™” í¬í•¨)
        for col in ["ì—´ì„¬ì§€ìˆ˜", "ë…¹ì§€ìœ¨", "ëƒ‰ë°©ë³´ê¸‰ë¥ "]:
            std_col = (merged[col] - merged[col].min()) / (merged[col].max() - merged[col].min())
            merged[f"{col}_std"] = std_col.fillna(0)

        merged["E"] = 0.5 * merged["ì—´ì„¬ì§€ìˆ˜_std"] + \
                      0.3 * (1 - merged["ë…¹ì§€ìœ¨_std"]) + \
                      0.2 * (1 - merged["ëƒ‰ë°©ë³´ê¸‰ë¥ _std"])

        # âœ… ì˜ˆì¸¡/ì‹¤ì œ í™˜ììˆ˜ ë¹„ìœ¨
        merged["ì˜ˆì¸¡í™˜ììˆ˜ë¹„ìœ¨"] = merged["ì˜ˆì¸¡í™˜ììˆ˜"] / ml_data["ì˜ˆì¸¡í™˜ììˆ˜"].max()
        merged["ì‹¤ì œí™˜ììˆ˜ë¹„ìœ¨"] = merged["í™˜ììˆ˜"] / ml_data["í™˜ììˆ˜"].max()

        # âœ… í”¼í•´ì ìˆ˜ ê³„ì‚°
        merged["í”¼í•´ì ìˆ˜"] = 10 * (
            0.4 * merged["S"] +
            0.3 * merged["E"] +
            0.2 * merged["ì˜ˆì¸¡í™˜ììˆ˜ë¹„ìœ¨"] +
            0.1 * merged["ì‹¤ì œí™˜ììˆ˜ë¹„ìœ¨"]
        )

        # âœ… ìœ„í—˜ë“±ê¸‰ í•¨ìˆ˜ ì •ì˜
        def score_to_grade(s):
            if s < 20: return "ğŸŸ¢ ë§¤ìš° ë‚®ìŒ"
            elif s < 30: return "ğŸŸ¡ ë‚®ìŒ"
            elif s < 40: return "ğŸŸ  ë³´í†µ"
            elif s < 50: return "ğŸ”´ ë†’ìŒ"
            else: return "ğŸ”¥ ë§¤ìš° ë†’ìŒ"

        merged["ìœ„í—˜ë“±ê¸‰"] = merged["í”¼í•´ì ìˆ˜"].apply(score_to_grade)

        # âœ… ë³´ìƒê¸ˆ ê³„ì‚° í•¨ìˆ˜ ì •ì˜
        def calc_payout(score):
            if score < 20: return 0
            elif score < 30: return 5000
            elif score < 40: return 10000
            elif score < 50: return 20000
            else: return 30000

        merged["ë³´ìƒê¸ˆ"] = merged["í”¼í•´ì ìˆ˜"].apply(calc_payout)

        # âœ… ê°€ì…ì ìˆ˜ ì…ë ¥ ë° ì´ ë³´ìƒê¸ˆ
        st.markdown("### ğŸ§¾ ê°€ì…ì ìˆ˜ ì…ë ¥")
        subs_count = st.number_input(f"{selected_gu} ê°€ì…ì ìˆ˜", min_value=0, step=1, key="subs_tab3")
        merged["ê°€ì…ììˆ˜"] = subs_count
        merged["ì˜ˆìƒì´ë³´ìƒê¸ˆ"] = merged["ë³´ìƒê¸ˆ"] * subs_count
        st.success(f"ğŸ’° ì˜ˆìƒ ë³´ìƒê¸ˆì•¡: {int(merged['ì˜ˆìƒì´ë³´ìƒê¸ˆ'].values[0]):,}ì›")

        # âœ… ê²°ê³¼ ì¶œë ¥
        show_cols = ["ìì¹˜êµ¬", "í”¼í•´ì ìˆ˜", "ìœ„í—˜ë“±ê¸‰", "ë³´ìƒê¸ˆ", "ê°€ì…ììˆ˜", "ì˜ˆìƒì´ë³´ìƒê¸ˆ"]
        st.dataframe(merged[show_cols], use_container_width=True)

        # âœ… CSV ë‹¤ìš´ë¡œë“œ
        csv_download = merged[show_cols]
        csv_bytes = csv_download.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_bytes,
            file_name=f"í”¼í•´ì ìˆ˜_{ymd}_{selected_gu}.csv",
            mime="text/csv"
        )

    except Exception as e:
        st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
